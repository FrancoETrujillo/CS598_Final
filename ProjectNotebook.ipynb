{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f954d686b0a84023",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2cda9f6d05930",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Team and Repo\n",
    "## Team Members:\n",
    "- Franco E.Trujillo - fet2@illinois.edu\n",
    "- Hongyi Wu - hongyiw6@illinois.edu\n",
    "\n",
    "## Project Repo:\n",
    "- [https://github.com/FrancoETrujillo/CS598_Final](https://github.com/FrancoETrujillo/CS598_Final)\n",
    "\n",
    "## Reference Repos:\n",
    "- [https://github.com/XZhang97666/MultimodalMIMIC](https://github.com/XZhang97666/MultimodalMIMIC)\n",
    "- [https://github.com/YerevaNN/mimic3-benchmarks](https://github.com/YerevaNN/mimic3-benchmarks)\n",
    "- [https://github.com/kaggarwal/ClinicalNotesICU](https://github.com/kaggarwal/ClinicalNotesICU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b40d117099b4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Introduction\n",
    "This paper pretends to address the challenges of handling irregularity and the integration of multimodal data for medical prediction tasks.\n",
    "\n",
    "## Background of the problem\n",
    "### What type of problem:\n",
    "The paper focuses on 2 main problems; Mortality Prediction and Phenotype Classification\n",
    "### What is the importance/meaning of solving the problem: \n",
    "ICUs admit patients with life-threatening conditions, Improving the efficacy and efficiency of predictions by accounting for irregular data in EHRs can help the medical providers to make more accurate and quick decisions that could save lives.\n",
    "\n",
    "### What is the difficulty of the problem:\n",
    "The primary difficulty is the handling the irregular sampling of data and the effective integration and modeling of EHR records like numerical time series and textual notes taken in multiple points in time and frequencies.\n",
    "\n",
    "![EHR sample image](.img/sample_ehr.png)\n",
    "\n",
    "### The state of the art methods and effectiveness.\n",
    "For irregular data handling;\n",
    "> [1] Lipton, Z. C., Kale, D., and Wetzel, R. Directly modeling\n",
    "> missing data in sequences with rnns: Improved classification of clinical time series. In Machine learning for\n",
    "> healthcare conference, pp. 253–270. PMLR, 2016.\n",
    "\n",
    "> [2] Shukla, S. N. and Marlin, B. M. Multi-time attention networks for irregularly sampled time series. arXiv preprint\n",
    "> arXiv:2101.10318, 2021.\n",
    "\n",
    "For irregular clinical notes processing;\n",
    "> [3] Golmaei, S. N. and Luo, X. Deepnote-gnn: predicting hospital readmission using clinical notes and patient network.\n",
    "> In Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics,\n",
    "> pp. 1–9, 2021.\n",
    "\n",
    "> [4]Mahbub, M., Srinivasan, S., Danciu, I., Peluso, A., Begoli, E., Tamang, S., and Peterson, G. D. \n",
    "> Unstructured clinical notes within the 24 hours since admission predict short,> mid & long-term mortality in adult icu patients. \n",
    "> Plos one, 17(1):e0262182, 2022.\n",
    "\n",
    "## Paper explanation\n",
    "### What did the paper propose\n",
    "The general problem addressed in this paper is to find a better approach to handling irregular multimodal data obtained on EHRs to better assess real-time predictions in ICUs. \n",
    "\n",
    "### What is the innovations of the method\n",
    "To better approach irregularity and multi-modal data the paper proposes integrating the real-time series and clinical notes while considering their irregularities. This by doing the following:\n",
    "\n",
    "![High level arch](.img/high_arch_w_desc.png)\n",
    "\n",
    "#### Modeling Irregularity in Time Series:\n",
    "1. Temporal Discretization-Based Embeddings (TDE): Utilizes a novel unified\n",
    "approach (UTDE) that combines:\n",
    "    - Imputation: Regularizes time series by filling in missing values based\n",
    "on prior observations or statistical methods.\n",
    "    - Discretized Multi-Time Attention (mTAND): Applies a learned\n",
    "interpolation method using a multi-time attention mechanism to\n",
    "represent the irregular time series data better.\n",
    "2. Unified Approach (UTDE): This approach integrates imputation and mTAND\n",
    "through a gating mechanism to dynamically combine the representation of\n",
    "the time series.\n",
    " \n",
    " ![Detail arch](.img/imputation_plus_mtand.png)\n",
    "\n",
    "#### Processing Irregular Clinical Notes:\n",
    "1. Text Encoding: Uses a pretrained model (TextEncoder) to encode clinical\n",
    "notes into a series of representations.\n",
    "2. Irregularity Modeling: Sorts these representations by time, treats them as\n",
    "Multivariate Irregularly Sampled Time Series (MINSTS), and employs mTAND\n",
    "to generate a set of text interpolation representations to handle irregularities.\n",
    "\n",
    "\n",
    "#### Multimodal Fusion:\n",
    "1. Interleaved Attention Mechanism: Fuses time series and clinical note\n",
    "representations across temporal steps, integrating irregularity into multimodal\n",
    "representations.\n",
    "2. Self and Cross-Attention:\n",
    "    - Multi-Head Self-Attention (MH): Acquires contextual embeddings for\n",
    "each modality by focusing within the same modality across time.\n",
    "    - Multi-Head Cross-Attention (CMH): Each modality learns from the\n",
    "other, integrating information across modalities.\n",
    "3. Feed-Forward and Prediction Layers: A feed-forward sublayer follows the\n",
    "CMH outputs, with layer normalization and residual connections applied. The\n",
    "final step involves passing the integrated representations through fully\n",
    "connected layers to predict the outcome.\n",
    "\n",
    "\n",
    "### How well the proposed method work (in its own metrics)\n",
    " The proposed methods for two medical prediction tasks consistently outperforms state-ofthe-art (SOTA) baselines in each single modality and multimodal fusion scenarios. \n",
    "Observing a relative improvements of 6.5%, 3.6%, and 4.3% in F1 for time series, clinical notes, and multimodal fusion, respectively. \n",
    "\n",
    "### What is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem).\n",
    "The paper's contribution is important because it provides a new direction for EHR-based predictive models to consider time irregularity that could lead to more accurate and reliable medical predictions, helping patients and healthcare processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091ff27ef282204",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Scope of Reproducibility:\n",
    "\n",
    "For our project we plan to reproduce the experiment with In Hospital Mortality (IHM). And prove the following hypotheses:\n",
    "\n",
    "\n",
    "1. The inclusion of UTDE improves the performance of the model.\n",
    "2. Considering irregularities in clinical note embedding improves the performance of the model.\n",
    "3. The introduction of UTDE and mTAND for processing time series and clinical notes, respectively, plus the integration of Multimodal fusion outperforms F1 score against standard baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf5f852216c24d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prerequisites to Reproduce the project\n",
    "- Get access to the MIMIC dataset\n",
    "- Modify the GlobalConfigs.py to use your own project and data paths\n",
    "- Install the required dependencies listed on Requirements.txt\n",
    "- Modify the directory variables on the **Configuring imports and directories** section bellow if needed\n",
    "\n",
    "**Note1** This project has being developed and tested using Linux Mint 21.2, ubuntu variants should work, but you may need to modify it to execute on another OS\n",
    "**Note2** More information about our dir structure can be found on our README.md \n",
    "**Note3** For this project we've used an NVDIA 4070 GPU with a limited dataset, you may need more resources for your case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d958f689e7c76",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Methodology\n",
    "\n",
    "The project reproduction consists on the following sections\n",
    "- Data\n",
    "- Models\n",
    "- Training\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fccbbee93bdeb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data\n",
    "\n",
    "This paper uses the MIMICIII dataset as starting point to obtain timeseries information and medical notes. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea0197a327d87e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " \n",
    "## Getting the data\n",
    " The following code contains some useful code to download and extract the dataset files locally\n",
    " \n",
    "**Note**: To download the mimic dataset is necessary to complete the request for access at [Physionet](https://physionet.org/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55643c225c7bfa5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Config tasks to execute\n",
    "Open and edit GlobalConfigs.py to set up the local path to the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e41a54007f74873",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:17.709563388Z",
     "start_time": "2024-04-14T03:54:17.561512068Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports and configs\n",
    "import subprocess\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import MultimodalMIMIC.preprocessing\n",
    "from GlobalConfigs import *\n",
    "\n",
    "DOWNLOAD_DATASET = False\n",
    "EXTRACT_COMPRESSED_CSVS = False\n",
    "PREPROCESS_BENCHMARKS = False\n",
    "PREPROCESS_CLINICAL_NOTES = False\n",
    "PREPROCESS_MULTIMODAL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b9290b2ec9b76",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd912cb01d3abcc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:17.790223088Z",
     "start_time": "2024-04-14T03:54:17.706745077Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change physionet_username to your username\n",
    "if DOWNLOAD_DATASET:\n",
    "\n",
    "    physionet_username = \"your_user_name\"\n",
    "    password = \"your_pass\"\n",
    "    destination_directory = \"data/MIMICIII_Original\"\n",
    "\n",
    "    command = [\n",
    "        \"wget\", \"-r\", \"-N\", \"-c\", \"-np\",\n",
    "        \"--user\", physionet_username,\n",
    "        \"--password\", password,\n",
    "        \"https://physionet.org/files/mimiciii/1.4/\",\n",
    "        \"-P\", destination_directory\n",
    "    ]\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Command failed with return code {process.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b7101051b10d00a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:17.841275719Z",
     "start_time": "2024-04-14T03:54:17.764319571Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if EXTRACT_COMPRESSED_CSVS:\n",
    "    command = ['./decompress_mimic.sh', '-d', 'data/MIMICIII_Original/physionet.org/files/mimiciii/1.4/', '-o',\n",
    "               'data/mimic3']\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Command failed with return code {process.returncode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee902ed9e8ef43",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preparing the data\n",
    "The original paper leverages the following projects to help on the data preparation and extraction from the original MIMIC CSVs\n",
    "\n",
    "It leverages the **mimic3-benchmarks** and the **ClinicalNotesICU** for the following:\n",
    "\n",
    "- Cleanup invalid data\n",
    "- Map the events, diagnoses, and stays for each patient.\n",
    "- Extract timeseries for in-hospital-mortality \n",
    "- Split timeseries data into train and test sets\n",
    "- Extract Medical notes for patients\n",
    "- Split Medical notes for train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63cceb7ae9be99",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MIMIC benchmarks\n",
    "Helps to process timeseries data and divide train and test sets\n",
    "[mimic3-benchmarks](https://github.com/YerevaNN/mimic3-benchmarks.git)\n",
    "\n",
    "This repo contains a set of scripts that take the RAW mimic CSVs and prepare the irregular data:\n",
    "- extract_subjects.py:\n",
    "Generates one directory per SUBJECT_ID and writes ICU stay information to data/{SUBJECT_ID}/stays.csv, diagnoses to data/{SUBJECT_ID}/diagnoses.csv, and events to data/{SUBJECT_ID}/events.csv\n",
    "\n",
    "\n",
    "- validate_events.py\n",
    "Attempts to fix some issues (ICU stay ID is missing) and removes the events that have missing information. About 80% of events remain after removing all suspicious rows\n",
    "\n",
    "\n",
    "- extract_episodes_from_subjects.py\n",
    "Breaks up per-subject data into separate episodes (pertaining to ICU stays). Time series of events are stored in {SUBJECT_ID}/episode{#}_timeseries.csv (where # counts distinct episodes) while episode-level information (patient age, gender, ethnicity, height, weight) and outcomes (mortality, length of stay, diagnoses) are stores in {SUBJECT_ID}/episode{#}.csv. This script requires two files, one that maps event ITEMIDs to clinical variables and another that defines valid ranges for clinical variables\n",
    "\n",
    "\n",
    "- split_train_and_test.py\n",
    "Splits the whole dataset into training and testing sets.\n",
    "\n",
    "\n",
    "- create_in_hospital_mortality.py\n",
    "Generate task-specific datasets for in-hospital-mortality prediction\n",
    "\n",
    "After running the preparation scripts we end up with a directory data/in-hospital-mortality we have two subdirectories: train and test. Each of them contains a bunch of ICU stays and one file with name listfile.csv, which lists all samples in that particular set. Each row of listfile.csv has the following form: icu_stay, period_length, label(s). A row specifies a sample for which the input is the collection of ICU event of icu_stay that occurred in the first period_length hours of the stay and the target are label(s). In in-hospital mortality prediction task period_length is always 48 hours.\n",
    "\n",
    "\n",
    "The project does not work out of the box, so we downloaded the sourcecode and modify it inside this repo under the [mimic3-benchmarks](./mimic3-benchmarks) folder\n",
    "To simplify the process we have created the following script `./build_benchmark_data.sh` to run all timeseries required tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "572e454792dbbde4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:17.898207630Z",
     "start_time": "2024-04-14T03:54:17.764497186Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if PREPROCESS_BENCHMARKS:\n",
    "    command = [\"./build_benchmark_data.sh\"]\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, shell=True)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Command failed with return code {process.returncode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f45bd0bc84d872",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ClinicalNotesICU\n",
    "Helps to process medical notes and divide in train and test\n",
    " [ClinicalNotesICU](https://github.com/kaggarwal/ClinicalNotesICU.git)\n",
    "\n",
    "Similar to the mimic3-benchmarks, this repo contains a set of scripts that take the RAW mimic CSVs and process the clinical notes for the previously generated train and test datasets.\n",
    "\n",
    "- extract_notes.py\n",
    "Uses the NOTEEVENTS.csv and the previously generated train and test sets to extract the notes within the first 48 hours of the event and saves them on its own train a test data directories \n",
    "\n",
    "- extract_T0.py\n",
    "Uses the stays.csv and events.csv to extract the episodes start time and save them into a binary pkl file.\n",
    "\n",
    "The project does not work out of the box, so we downloaded the sourcecode and modify it inside this repo under the [ClinicalNotesICU](./ClinicalNotesICU) folder\n",
    "\n",
    "To simplify the process we have created the following script `./extract_med_notes.sh` tu run all the required tasks for clinical notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d23722350fecd73f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:17.899719945Z",
     "start_time": "2024-04-14T03:54:17.796592704Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if PREPROCESS_CLINICAL_NOTES:\n",
    "    command = [\"./extract_med_notes.sh\"]\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, shell=True)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Command failed with return code {process.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839edc8722b2b0e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocess time series For Mimic Multimodal \n",
    "The next step is to discretize and normalize the timeseries data, as well as link the clinical notes with their corresponding timestamps.\n",
    "\n",
    "The [paper's repo](https://github.com/XZhang97666/MultimodalMIMIC.git) provides a preprocessing script to work on this task.\n",
    "\n",
    "After running the preprocessing steps we save the following PKLs to be used by the model: \n",
    "```\n",
    "mean_std.pkl \n",
    "norm_ts_test.pkl\n",
    "norm_ts_train.pkl\n",
    "norm_ts_val.pkl\n",
    "testp2x_data.pkl\n",
    "trainp2x_data.pkl\n",
    "ts_test.pkl\n",
    "ts_train.pkl\n",
    "ts_val.pkl\n",
    "valp2x_data.pkl\n",
    "```\n",
    "The project does not work out of the box, so we used it partially to call some of the functions from this notebook; the downloaded sourcecode and modifications are inside this repo under the [MultimodalMIMIC](./MultimodalMIMIC) folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d88a4406872a51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Configuring imports and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ed034beed47eeaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:17.900836493Z",
     "start_time": "2024-04-14T03:54:17.839657654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mimic3benchmark.readers import InHospitalMortalityReader\n",
    "from MultimodalMIMIC.preprocessing import Discretizer_multi\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, Any\n",
    "from readers import Reader\n",
    "import gzip\n",
    "from mimic3models.preprocessing import Normalizer\n",
    "from MultimodalMIMIC.preprocessing import extract_irregular\n",
    "from MultimodalMIMIC.preprocessing import mean_std\n",
    "from MultimodalMIMIC.preprocessing import normalize\n",
    "from MultimodalMIMIC.text_utils import TextReader\n",
    "from MultimodalMIMIC.preprocessing import merge_text_ts\n",
    "\n",
    "\n",
    "GENERATE_PREPROCESSED_PKL = True\n",
    "\n",
    "# Paths for data\n",
    "ihm_data_path = f\"{BENCHMARKS_ROOT_PATH}/data/in-hospital-mortality\"\n",
    "ihm_train_data_path = f\"{ihm_data_path}/train\"\n",
    "ihm_test_data_path = f\"{ihm_data_path}/test\"\n",
    "discretizer_config_path = f\"{MULTI_MODAL_MIMIC_PATH}/Data/irregular/discretizer_config.json\"\n",
    "channel_info_path = f\"{MULTI_MODAL_MIMIC_PATH}/Data/irregular/channel_info.json\"\n",
    "textdata_fixed = f\"{BENCHMARKS_ROOT_PATH}/data/root/text_fixed/train/\"\n",
    "text_start_time_path = f\"{BENCHMARKS_ROOT_PATH}/data/root/text_fixed/starttime.pkl\"\n",
    "test_textdata_fixed = f\"{BENCHMARKS_ROOT_PATH}/data/root/text_fixed/test/\"\n",
    "test_text_start_time_path = f\"{BENCHMARKS_ROOT_PATH}/data/root/text_fixed/test_starttime.pkl\"\n",
    "ihm_discrete_save_path = f\"{MULTI_MODAL_MIMIC_PATH}/Data/ihm/\"\n",
    "\n",
    "# Modify this to take only a subset of the full data; None takes the full data\n",
    "n_samples_elements = 1000\n",
    "\n",
    "mortality_period = 48\n",
    "timestep = 1.0\n",
    "imputation = \"previous\"\n",
    "dataset_types = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "normalizer_state_file_path = f'{BENCHMARKS_ROOT_PATH}/mimic3models/in_hospital_mortality/ihm_ts{timestep}.input_str-{imputation}.start_time-zero.normalizer'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972d061613ed073",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Reading the data\n",
    "First define the InHospitalMortalityReader to help us easily access the split datasets generated by mimic3-benchmarks. It provides helper functions to read multiple data series samples and labels by patient and map to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f0db8b42d1f1ab5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:17.953744737Z",
     "start_time": "2024-04-14T03:54:17.890164864Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    train_reader = InHospitalMortalityReader(dataset_dir=ihm_train_data_path,\n",
    "                                             listfile=os.path.join(ihm_train_data_path, 'listfile.csv'),\n",
    "                                             period_length=mortality_period)\n",
    "    val_reader = InHospitalMortalityReader(dataset_dir=ihm_train_data_path,\n",
    "                                           listfile=os.path.join(ihm_train_data_path, 'listfile.csv'),\n",
    "                                           period_length=mortality_period)\n",
    "    \n",
    "    test_reader = InHospitalMortalityReader(dataset_dir=ihm_test_data_path,\n",
    "                                            listfile=os.path.join(ihm_test_data_path, 'listfile.csv'),\n",
    "                                            period_length=mortality_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e05696cbeab2d89a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:17.963677070Z",
     "start_time": "2024-04-14T03:54:17.941491983Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_compressed_pkl_gz(data_to_dump: Any, save_name: str):\n",
    "    print(\"saving and compressing:\", save_name)\n",
    "    with gzip.open(f'{save_name}.pkl.gz', 'wb') as file:\n",
    "        pickle.dump(data_to_dump, file)\n",
    "\n",
    "\n",
    "def load_compressed_pkl(full_file_name: str) -> Any:\n",
    "    with gzip.open(full_file_name, 'rb') as file:\n",
    "        data_loaded = pickle.load(file)\n",
    "    return data_loaded\n",
    "\n",
    "\n",
    "def read_chunk(reader, chunk_size):\n",
    "    chunk_data = {}\n",
    "    for _ in tqdm(range(chunk_size), desc=\"reading data\"):\n",
    "        ret = reader.read_next()\n",
    "        for k, v in ret.items():\n",
    "            if k not in chunk_data:\n",
    "                chunk_data[k] = []\n",
    "            chunk_data[k].append(v)\n",
    "    chunk_data[\"header\"] = chunk_data[\"header\"][0]\n",
    "    return chunk_data\n",
    "\n",
    "\n",
    "def discretize_and_save_data(reader: Reader, discretizer: Discretizer_multi, save_path: str,\n",
    "                             partial_n_samples: Optional[int] = None, save_name=str, compress_pkl: bool = False):\n",
    "    n_samples = reader.get_number_of_examples()\n",
    "    if partial_n_samples:\n",
    "        n_samples = partial_n_samples\n",
    "    ret = read_chunk(reader, n_samples)\n",
    "    irg_data = ret[\"X\"]\n",
    "    ts = ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    discrete_names = ret[\"name\"]\n",
    "\n",
    "    reg_data = []\n",
    "    for X, t in tqdm(zip(irg_data, ts), total=len(irg_data), desc=f\"discretizing data \"):\n",
    "        transformed_data = discretizer.transform(X, end=t)[0]\n",
    "        reg_data.append(transformed_data)\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_full_path = save_path + save_name\n",
    "    if compress_pkl:\n",
    "        save_compressed_pkl_gz((irg_data, reg_data, labels, discrete_names), save_full_path)\n",
    "    else:\n",
    "        print(\"Saving\", f\"{save_full_path}.pkl\")\n",
    "        with open(f\"{save_full_path}.pkl\", 'wb') as file:\n",
    "            pickle.dump((irg_data, reg_data, labels, discrete_names), file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba45dd4edd24c95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Discretize temporal data and add imputation\n",
    "\n",
    "In order to create the embeddings for the proposed model first we need to discretize and add the imputation to the missing values. In our case we will use imputation using the previous value of the series.\n",
    "\n",
    "The Discretizer_multi takes care of transforming the irregular data into samples at each timestep while filling the missing data with the desired imputation strategy considering all time based features.\n",
    "\n",
    "![Discretizer image](.img/only_discretize.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5be5a812eb8f9ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:28.282632479Z",
     "start_time": "2024-04-14T03:54:17.963868061Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discretize and save train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data: 100%|██████████| 1000/1000 [00:00<00:00, 1550.87it/s]\n",
      "discretizing data : 100%|██████████| 1000/1000 [00:02<00:00, 359.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/ts_train.pkl\n",
      "discretize and save val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data: 100%|██████████| 1000/1000 [00:00<00:00, 2005.90it/s]\n",
      "discretizing data : 100%|██████████| 1000/1000 [00:01<00:00, 519.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/ts_val.pkl\n",
      "discretize and save test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data: 100%|██████████| 1000/1000 [00:00<00:00, 2243.09it/s]\n",
      "discretizing data : 100%|██████████| 1000/1000 [00:01<00:00, 562.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/ts_test.pkl\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    discretizer_multi = Discretizer_multi(\n",
    "        impute_strategy='previous',\n",
    "        store_masks=True,\n",
    "        start_time='zero',\n",
    "        config_path=discretizer_config_path,\n",
    "        channel_path=channel_info_path\n",
    "    )\n",
    "    discretizer_header = discretizer_multi.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n",
    "    cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n",
    "\n",
    "    \n",
    "    print(\"discretize and save train\")\n",
    "    discretize_and_save_data(train_reader, discretizer_multi, ihm_discrete_save_path, n_samples_elements, \"ts_train\")\n",
    "    print(\"discretize and save val\")\n",
    "    discretize_and_save_data(val_reader, discretizer_multi, ihm_discrete_save_path, n_samples_elements, \"ts_val\")\n",
    "    print(\"discretize and save test\")\n",
    "    discretize_and_save_data(test_reader, discretizer_multi, ihm_discrete_save_path, n_samples_elements, \"ts_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f129af1f21d395",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Paddings and masks\n",
    "After discretize we need to apply paddings and create masks for all features. For this we can use the function extract_irregular from MultimodalMimic. It creates the padded irregular and mask arrays and save them for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72092e5bc118117e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:32.159360331Z",
     "start_time": "2024-04-14T03:54:28.284294467Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train irregular data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/ts_train.pkl\n",
      "Extracting val irregular data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/ts_val.pkl\n",
      "Extracting test irregular data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/ts_test.pkl\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    for dataset_type in dataset_types:\n",
    "        print(f\"Extracting {dataset_type} irregular data\", flush=True)\n",
    "        in_extract_data_path = ihm_discrete_save_path + 'ts_' + dataset_type + '.pkl'\n",
    "        out_extract_data_path = ihm_discrete_save_path + 'ts_' + dataset_type + '.pkl'\n",
    "        extract_irregular(in_extract_data_path, out_extract_data_path, channel_info_path, discretizer_config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "acce6019f9e94910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:33.530110631Z",
     "start_time": "2024-04-14T03:54:32.161684639Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/mean_std.pkl\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    mean_std(ihm_discrete_save_path + 'ts_train.pkl', ihm_discrete_save_path + 'mean_std.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407668b846604ce6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalizing timeseries data\n",
    "Now we apply normalization to our data by x = (x - means[f_idx]) / stds[f_idx], For this, we leverage the Normalizer provided by the mimic3-benchmarks repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b6d118f0c2f7865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:36.604668551Z",
     "start_time": "2024-04-14T03:54:33.529753837Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing train times data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/norm_ts_train.pkl\n",
      "Normalizing val times data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/norm_ts_val.pkl\n",
      "Normalizing test times data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/norm_ts_test.pkl\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    normalizer = Normalizer(fields=cont_channels)\n",
    "    normalizer.load_params(normalizer_state_file_path)\n",
    "    \n",
    "    for dataset_type in dataset_types:\n",
    "        print(f\"Normalizing {dataset_type} times data\", flush=True)\n",
    "        normalize(ihm_discrete_save_path + 'ts_' + dataset_type + '.pkl',\n",
    "                  ihm_discrete_save_path + 'norm_ts_' + dataset_type + '.pkl',\n",
    "              ihm_discrete_save_path + 'mean_std.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef855063840a6659",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preparing the Text data\n",
    "We finally prepare the text data within a period (48 in our case) and generate a json containing the note as well as the time until the end of the period. For this we use the TextReader helper from the MultimodalMIMIC module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae28b8cd4f293522",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:39.211068764Z",
     "start_time": "2024-04-14T03:54:36.605375606Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing  train text data\n",
      "Suceed Merging:  750\n",
      "Missing Merging:  250\n",
      "File dumped at: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/trainp2x_data.pkl\n",
      "Preparing  val text data\n",
      "Suceed Merging:  750\n",
      "Missing Merging:  250\n",
      "File dumped at: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/valp2x_data.pkl\n",
      "Preparing  test text data\n",
      "Suceed Merging:  762\n",
      "Missing Merging:  238\n",
      "File dumped at: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/testp2x_data.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    for dataset_type in dataset_types:\n",
    "        print(f\"Preparing  {dataset_type} text data\", flush=True)\n",
    "    \n",
    "        with open(ihm_discrete_save_path + 'norm_ts_' + dataset_type + '.pkl', 'rb') as f:\n",
    "            tsdata = pickle.load(f)\n",
    "    \n",
    "        names = [data['name'] for data in tsdata]\n",
    "    \n",
    "        if (dataset_type == 'train') or (dataset_type == 'val'):\n",
    "            text_reader = TextReader(textdata_fixed, text_start_time_path)\n",
    "        else:\n",
    "            text_reader = TextReader(test_textdata_fixed, test_text_start_time_path)\n",
    "    \n",
    "        data_text, data_times, data_time = text_reader.read_all_text_append_json(names, mortality_period)\n",
    "        merge_text_ts(data_text, data_times, data_time, tsdata, mortality_period,\n",
    "                      ihm_discrete_save_path + dataset_type + 'p2x_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea129f0ca6817b1b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742c8dbf677eb5a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## import required module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d5c0d798e3e52fc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:39.252216019Z",
     "start_time": "2024-04-14T03:54:39.213204606Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "sys.path.insert(0, 'MultimodalMIMIC')\n",
    "from GlobalConfigs import *\n",
    "from model import *\n",
    "from train import *\n",
    "from checkpoint import *\n",
    "from util import *\n",
    "from accelerate import Accelerator\n",
    "from interp import *\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf6062fd6a39c7d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## set arguments\n",
    "\n",
    "this step is to set up parameter to set up how to train and evaluatate the model.\n",
    "\n",
    "here we only train the model for 1 epoch for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3ebe52b12edd5709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:39.289283292Z",
     "start_time": "2024-04-14T03:54:39.247089590Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'ihm', 'file_path': '/media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/', 'output_dir': 'run/TS_Text', 'tensorboard_dir': None, 'seed': 42, 'mode': 'train', 'modeltype': 'TS_Text', 'eval_score': ['auc', 'auprc', 'f1'], 'num_labels': 2, 'max_length': 1024, 'pad_to_max_length': False, 'model_path': None, 'train_batch_size': 2, 'eval_batch_size': 8, 'num_update_bert_epochs': 2, 'num_train_epochs': 1, 'txt_learning_rate': 5e-05, 'ts_learning_rate': 0.0004, 'gradient_accumulation_steps': 16, 'weight_decay': 0.01, 'lr_scheduler_type': 'linear', 'pt_mask_ratio': 0.15, 'mean_mask_length': 3, 'chunk': False, 'chunk_type': 'sent_doc_pos', 'warmup_proportion': 0.1, 'kernel_size': 1, 'num_heads': 8, 'layers': 3, 'cross_layers': 3, 'embed_dim': 128, 'irregular_learn_emb_ts': True, 'irregular_learn_emb_text': True, 'reg_ts': True, 'tt_max': 48, 'embed_time': 64, 'ts_to_txt': False, 'txt_to_ts': False, 'dropout': 0.1, 'model_name': 'bioLongformer', 'num_of_notes': 5, 'notes_order': 'Last', 'ratio_notes_order': None, 'bertcount': 3, 'first_n_item': 3, 'fine_tune': False, 'self_cross': False, 'TS_mixup': False, 'mixup_level': 'batch', 'fp16': True, 'debug': False, 'generate_data': False, 'FTLSTM': False, 'Interp': False, 'cpu': False, 'datagereate_seed': 42, 'TS_model': 'Atten', 'cross_method': 'self_cross'}\n"
     ]
    }
   ],
   "source": [
    "ihm_discrete_save_path = f'{MULTI_MODAL_MIMIC_PATH}/Data/ihm' if ihm_discrete_save_path is None else ihm_discrete_save_path\n",
    "\n",
    "parser = parse_args()\n",
    "args = parser.parse_args(['--num_train_epochs','1',\n",
    "                         '--train_batch_size','2',\n",
    "                         '--eval_batch_size','8',\n",
    "                         '--gradient_accumulation_steps','16',\n",
    "                         '--num_update_bert_epochs','2',\n",
    "                         '--notes_order','Last',\n",
    "                         '--max_length','1024',\n",
    "                         '--output_dir','run/TS_Text',\n",
    "                         '--embed_dim','128',\n",
    "                         '--model_name','bioLongformer',\n",
    "                         '--file_path',f'{ihm_discrete_save_path}',\n",
    "                         '--mixup_level','batch',\n",
    "                         '--fp16',\n",
    "                         '--irregular_learn_emb_text',\n",
    "                         '--irregular_learn_emb_ts',\n",
    "                         '--reg_ts'])\n",
    "\n",
    "\n",
    "print(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5545519ecc6bcd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Set up training environment\n",
    "\n",
    "based on given argument above, set up the training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8001c7cfaa4a4ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:39.324212176Z",
     "start_time": "2024-04-14T03:54:39.288961143Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "run/TS_Text/ihm/TS_Text/TS_48/Atten/Text_48/bioLongformer/1024/cross_attn3/irregular_TS_64/irregular_Text_64/5e-05_2_3_0.0004_1_8_128_1_2/\n"
     ]
    }
   ],
   "source": [
    "if args.fp16:\n",
    "        args.mixed_precision = \"fp16\"\n",
    "else:\n",
    "    args.mixed_precision = \"no\"\n",
    "accelerator = Accelerator(mixed_precision=args.mixed_precision, cpu=args.cpu)\n",
    "\n",
    "device = accelerator.device\n",
    "print(f'device: {device}')\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "if args.tensorboard_dir != None:\n",
    "    writer = SummaryWriter(args.tensorboard_dir)\n",
    "else:\n",
    "    writer = None\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed)\n",
    "\n",
    "output_path = make_save_dir(args)\n",
    "\n",
    "if args.seed == 0:\n",
    "    copy_file(args.ck_file_path + 'model/', src=os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fe1b9546a9eac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load data\n",
    "\n",
    "Load training, validation and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1abb566257e28182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:39.995774692Z",
     "start_time": "2024-04-14T03:54:39.317435693Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franco Trying to load: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/trainp2x_data.pkl\n",
      "Using /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/trainp2x_data.pkl\n",
      "Franco Trying to load: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/valp2x_data.pkl\n",
      "Using /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/valp2x_data.pkl\n",
      "Franco Trying to load: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/testp2x_data.pkl\n",
      "Using /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm/testp2x_data.pkl\n"
     ]
    }
   ],
   "source": [
    "if args.mode == 'train':\n",
    "        if 'Text' in args.modeltype:\n",
    "            BioBert, BioBertConfig, tokenizer = loadBert(args, device)\n",
    "        else:\n",
    "            BioBert, tokenizer = None, None\n",
    "        train_dataset, train_sampler, train_dataloader = data_perpare(args, 'train', tokenizer)\n",
    "        val_dataset, val_sampler, val_dataloader = data_perpare(args, 'val', tokenizer)\n",
    "        _, _, test_data_loader = data_perpare(args, 'test', tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36408e5fb15eac2f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load model\n",
    "\n",
    "load model from model python.\n",
    "for full model implementation, check github.\n",
    "\n",
    "based on given argument model type, the below code will load one of two models.\n",
    "\n",
    "- MULTCrossModel:\n",
    "  - This is a multi-modal cross model. It combines both text and time series data. Depending on the configuration, it may employ Transformer encoders for processing time series data and apply attention mechanisms for processing text embeddings. The model integrates text and time series data at different levels using various fusion techniques such as self-cross attention or cross-modal fusion. Again, the output depends on the task (ihm or pheno), and appropriate loss functions are used accordingly.\n",
    "- \n",
    "TSMixed\n",
    "  - This is a mixed model for time series data. It combines interpolation techniques, such as S_Interp and Cross_Interp, with Transformer-based encoders or other models like LSTM or CNN for processing time series data. It handles mixed-level data, such as batch-level, sequence-level, or feature-level mixup, and outputs predictions based on the task (ihm or pheno)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17d700490ade34",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![high level arch with desc](.img/high_arch_w_desc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7814a16c38a9b49c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T03:54:40.048729359Z",
     "start_time": "2024-04-14T03:54:39.995074851Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'Text' in args.modeltype:\n",
    "    model = MULTCrossModel(args=args, device=device, orig_d_ts=17, orig_reg_d_ts=34, orig_d_txt=768,\n",
    "                           ts_seq_num=args.tt_max, text_seq_num=args.num_of_notes, Biobert=BioBert)\n",
    "else:\n",
    "    model = TSMixed(args=args, device=device, orig_d_ts=17, orig_reg_d_ts=34, ts_seq_num=args.tt_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c72c29e3d47c1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## train\n",
    "\n",
    "This part of code train model. \n",
    "Given modeltype argument from above, it will set optimizer for different model type. (Text, Timeseries or mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a458eff6e7e8cbc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T04:00:21.821699237Z",
     "start_time": "2024-04-14T03:54:40.040522415Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "362it [01:59,  3.24it/s]\u001B[A\n",
      "363it [02:00,  2.78it/s]\u001B[A\n",
      "364it [02:00,  2.60it/s]\u001B[A\n",
      "365it [02:01,  2.44it/s]\u001B[A\n",
      "366it [02:01,  2.36it/s]\u001B[A\n",
      "367it [02:02,  2.36it/s]\u001B[A\n",
      "368it [02:02,  2.65it/s]\u001B[A\n",
      "369it [02:02,  2.92it/s]\u001B[A\n",
      "370it [02:03,  2.75it/s]\u001B[A\n",
      "371it [02:03,  3.09it/s]\u001B[A\n",
      "372it [02:03,  2.86it/s]\u001B[A\n",
      "373it [02:04,  2.74it/s]\u001B[A\n",
      "374it [02:04,  3.07it/s]\u001B[A\n",
      "375it [02:04,  2.88it/s]\u001B[A\n",
      "376it [02:04,  3.17it/s]\u001B[A\n",
      "377it [02:05,  2.95it/s]\u001B[A\n",
      "378it [02:05,  2.82it/s]\u001B[A\n",
      "379it [02:05,  3.14it/s]\u001B[A\n",
      "380it [02:06,  2.94it/s]\u001B[A\n",
      "381it [02:06,  3.26it/s]\u001B[A\n",
      "382it [02:06,  3.51it/s]\u001B[A\n",
      "383it [02:07,  3.15it/s]\u001B[A\n",
      "384it [02:07,  2.95it/s]\u001B[A\n",
      "385it [02:07,  3.27it/s]\u001B[A\n",
      "386it [02:08,  3.04it/s]\u001B[A\n",
      "387it [02:08,  3.34it/s]\u001B[A\n",
      "388it [02:08,  3.09it/s]\u001B[A\n",
      "389it [02:09,  3.35it/s]\u001B[A\n",
      "390it [02:09,  3.08it/s]\u001B[A\n",
      "391it [02:09,  3.39it/s]\u001B[A\n",
      "392it [02:09,  3.64it/s]\u001B[A\n",
      "393it [02:10,  3.23it/s]\u001B[A\n",
      "394it [02:10,  2.99it/s]\u001B[A\n",
      "395it [02:11,  2.80it/s]\u001B[A\n",
      "396it [02:11,  2.72it/s]\u001B[A\n",
      "397it [02:11,  2.66it/s]\u001B[A\n",
      "398it [02:12,  2.99it/s]\u001B[A\n",
      "399it [02:12,  2.85it/s]\u001B[A\n",
      "400it [02:12,  3.15it/s]\u001B[A\n",
      "401it [02:13,  2.91it/s]\u001B[A\n",
      "402it [02:13,  2.79it/s]\u001B[A\n",
      "403it [02:13,  3.10it/s]\u001B[A\n",
      "404it [02:14,  2.91it/s]\u001B[A\n",
      "405it [02:14,  3.20it/s]\u001B[A\n",
      "406it [02:14,  3.48it/s]\u001B[A\n",
      "407it [02:14,  3.67it/s]\u001B[A\n",
      "408it [02:15,  3.22it/s]\u001B[A\n",
      "409it [02:15,  3.45it/s]\u001B[A\n",
      "410it [02:15,  3.13it/s]\u001B[A\n",
      "411it [02:16,  3.39it/s]\u001B[A\n",
      "412it [02:16,  3.01it/s]\u001B[A\n",
      "413it [02:16,  3.27it/s]\u001B[A\n",
      "414it [02:17,  3.47it/s]\u001B[A\n",
      "415it [02:17,  3.13it/s]\u001B[A\n",
      "416it [02:17,  3.39it/s]\u001B[A\n",
      "417it [02:17,  3.63it/s]\u001B[A\n",
      "418it [02:18,  3.80it/s]\u001B[A\n",
      "419it [02:18,  3.32it/s]\u001B[A\n",
      "420it [02:18,  3.56it/s]\u001B[A\n",
      "421it [02:19,  3.16it/s]\u001B[A\n",
      "422it [02:19,  2.93it/s]\u001B[A\n",
      "423it [02:19,  2.80it/s]\u001B[A\n",
      "424it [02:20,  2.70it/s]\u001B[A\n",
      "425it [02:20,  3.04it/s]\u001B[A\n",
      "426it [02:20,  3.30it/s]\u001B[A\n",
      "427it [02:21,  3.01it/s]\u001B[A\n",
      "428it [02:21,  2.84it/s]\u001B[A\n",
      "429it [02:22,  2.75it/s]\u001B[A\n",
      "430it [02:22,  2.68it/s]\u001B[A\n",
      "431it [02:22,  3.03it/s]\u001B[A\n",
      "432it [02:23,  2.82it/s]\u001B[A\n",
      "433it [02:23,  3.12it/s]\u001B[A\n",
      "434it [02:23,  3.37it/s]\u001B[A\n",
      "435it [02:23,  3.57it/s]\u001B[A\n",
      "436it [02:24,  3.12it/s]\u001B[A\n",
      "437it [02:24,  3.37it/s]\u001B[A\n",
      "438it [02:24,  3.59it/s]\u001B[A\n",
      "439it [02:24,  3.66it/s]\u001B[A\n",
      "440it [02:25,  3.19it/s]\u001B[A\n",
      "441it [02:25,  3.41it/s]\u001B[A\n",
      "442it [02:26,  3.03it/s]\u001B[A\n",
      "443it [02:26,  3.26it/s]\u001B[A\n",
      "444it [02:26,  2.94it/s]\u001B[A\n",
      "445it [02:27,  2.75it/s]\u001B[A\n",
      "446it [02:27,  3.08it/s]\u001B[A\n",
      "447it [02:27,  2.86it/s]\u001B[A\n",
      "448it [02:28,  2.64it/s]\u001B[A\n",
      "449it [02:28,  2.96it/s]\u001B[A\n",
      "450it [02:28,  2.84it/s]\u001B[A\n",
      "451it [02:29,  2.72it/s]\u001B[A\n",
      "452it [02:29,  2.64it/s]\u001B[A\n",
      "453it [02:30,  2.61it/s]\u001B[A\n",
      "454it [02:30,  2.95it/s]\u001B[A\n",
      "455it [02:30,  2.81it/s]\u001B[A\n",
      "456it [02:31,  2.70it/s]\u001B[A\n",
      "457it [02:31,  2.65it/s]\u001B[A\n",
      "458it [02:31,  2.61it/s]\u001B[A\n",
      "459it [02:32,  2.59it/s]\u001B[A\n",
      "460it [02:32,  2.58it/s]\u001B[A\n",
      "461it [02:33,  2.58it/s]\u001B[A\n",
      "462it [02:33,  2.93it/s]\u001B[A\n",
      "463it [02:33,  2.82it/s]\u001B[A\n",
      "464it [02:33,  3.12it/s]\u001B[A\n",
      "465it [02:34,  2.95it/s]\u001B[A\n",
      "466it [02:34,  3.24it/s]\u001B[A\n",
      "467it [02:34,  2.99it/s]\u001B[A\n",
      "468it [02:35,  2.86it/s]\u001B[A\n",
      "469it [02:35,  3.19it/s]\u001B[A\n",
      "470it [02:35,  3.44it/s]\u001B[A\n",
      "471it [02:35,  3.66it/s]\u001B[A\n",
      "472it [02:36,  3.24it/s]\u001B[A\n",
      "473it [02:36,  2.99it/s]\u001B[A\n",
      "474it [02:37,  2.86it/s]\u001B[A\n",
      "475it [02:37,  2.76it/s]\u001B[A\n",
      "476it [02:37,  2.69it/s]\u001B[A\n",
      "477it [02:38,  3.04it/s]\u001B[A\n",
      "478it [02:38,  2.89it/s]\u001B[A\n",
      "479it [02:38,  2.78it/s]\u001B[A\n",
      "480it [02:39,  2.70it/s]\u001B[A\n",
      "481it [02:39,  2.67it/s]\u001B[A\n",
      "482it [02:39,  2.96it/s]\u001B[A\n",
      "483it [02:40,  3.26it/s]\u001B[A\n",
      "484it [02:40,  3.51it/s]\u001B[A\n",
      "485it [02:40,  3.71it/s]\u001B[A\n",
      "486it [02:40,  3.87it/s]\u001B[A\n",
      "487it [02:41,  3.35it/s]\u001B[A\n",
      "488it [02:41,  3.04it/s]\u001B[A\n",
      "489it [02:41,  3.27it/s]\u001B[A\n",
      "490it [02:42,  3.50it/s]\u001B[A\n",
      "491it [02:42,  3.69it/s]\u001B[A\n",
      "492it [02:42,  3.85it/s]\u001B[A\n",
      "493it [02:43,  3.34it/s]\u001B[A\n",
      "494it [02:43,  3.58it/s]\u001B[A\n",
      "495it [02:43,  3.20it/s]\u001B[A\n",
      "496it [02:44,  2.96it/s]\u001B[A\n",
      "497it [02:44,  3.25it/s]\u001B[A\n",
      "498it [02:44,  3.49it/s]\u001B[A\n",
      "499it [02:44,  3.14it/s]\u001B[A\n",
      "500it [02:45,  3.03it/s]\u001B[A\n",
      "\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]\u001B[A\n",
      "  1%|          | 1/125 [00:01<02:56,  1.42s/it]\u001B[A\n",
      "  2%|▏         | 2/125 [00:02<02:51,  1.39s/it]\u001B[A\n",
      "  2%|▏         | 3/125 [00:04<02:49,  1.39s/it]\u001B[A\n",
      "  3%|▎         | 4/125 [00:05<02:47,  1.39s/it]\u001B[A\n",
      "  4%|▍         | 5/125 [00:06<02:45,  1.38s/it]\u001B[A\n",
      "  5%|▍         | 6/125 [00:08<02:44,  1.38s/it]\u001B[A\n",
      "  6%|▌         | 7/125 [00:09<02:43,  1.39s/it]\u001B[A\n",
      "  6%|▋         | 8/125 [00:11<02:42,  1.39s/it]\u001B[A\n",
      "  7%|▋         | 9/125 [00:12<02:41,  1.39s/it]\u001B[A\n",
      "  8%|▊         | 10/125 [00:13<02:38,  1.38s/it]\u001B[A\n",
      "  9%|▉         | 11/125 [00:15<02:37,  1.38s/it]\u001B[A\n",
      " 10%|▉         | 12/125 [00:16<02:37,  1.39s/it]\u001B[A\n",
      " 10%|█         | 13/125 [00:18<02:35,  1.39s/it]\u001B[A\n",
      " 11%|█         | 14/125 [00:19<02:33,  1.38s/it]\u001B[A\n",
      " 12%|█▏        | 15/125 [00:20<02:31,  1.38s/it]\u001B[A\n",
      " 13%|█▎        | 16/125 [00:22<02:30,  1.38s/it]\u001B[A\n",
      " 14%|█▎        | 17/125 [00:23<02:31,  1.41s/it]\u001B[A\n",
      " 14%|█▍        | 18/125 [00:25<02:33,  1.44s/it]\u001B[A\n",
      " 15%|█▌        | 19/125 [00:26<02:31,  1.43s/it]\u001B[A\n",
      " 16%|█▌        | 20/125 [00:27<02:28,  1.42s/it]\u001B[A\n",
      " 17%|█▋        | 21/125 [00:29<02:21,  1.36s/it]\u001B[A\n",
      " 18%|█▊        | 22/125 [00:30<02:21,  1.37s/it]\u001B[A\n",
      " 18%|█▊        | 23/125 [00:31<02:20,  1.38s/it]\u001B[A\n",
      " 19%|█▉        | 24/125 [00:33<02:18,  1.38s/it]\u001B[A\n",
      " 20%|██        | 25/125 [00:34<02:02,  1.22s/it]\u001B[A\n",
      " 21%|██        | 26/125 [00:35<02:07,  1.28s/it]\u001B[A\n",
      " 22%|██▏       | 27/125 [00:37<02:08,  1.32s/it]\u001B[A\n",
      " 22%|██▏       | 28/125 [00:38<02:09,  1.33s/it]\u001B[A\n",
      " 23%|██▎       | 29/125 [00:39<02:09,  1.35s/it]\u001B[A\n",
      " 24%|██▍       | 30/125 [00:41<02:09,  1.36s/it]\u001B[A\n",
      " 25%|██▍       | 31/125 [00:42<02:08,  1.37s/it]\u001B[A\n",
      " 26%|██▌       | 32/125 [00:43<02:07,  1.37s/it]\u001B[A\n",
      " 26%|██▋       | 33/125 [00:44<01:48,  1.18s/it]\u001B[A\n",
      " 27%|██▋       | 34/125 [00:46<01:54,  1.26s/it]\u001B[A\n",
      " 28%|██▊       | 35/125 [00:47<01:58,  1.32s/it]\u001B[A\n",
      " 29%|██▉       | 36/125 [00:48<01:59,  1.34s/it]\u001B[A\n",
      " 30%|██▉       | 37/125 [00:50<02:00,  1.37s/it]\u001B[A\n",
      " 30%|███       | 38/125 [00:51<02:01,  1.39s/it]\u001B[A\n",
      " 31%|███       | 39/125 [00:53<01:59,  1.39s/it]\u001B[A\n",
      " 32%|███▏      | 40/125 [00:54<01:57,  1.38s/it]\u001B[A\n",
      " 33%|███▎      | 41/125 [00:55<01:56,  1.39s/it]\u001B[A\n",
      " 34%|███▎      | 42/125 [00:57<01:55,  1.40s/it]\u001B[A\n",
      " 34%|███▍      | 43/125 [00:58<01:53,  1.39s/it]\u001B[A\n",
      " 35%|███▌      | 44/125 [01:00<01:52,  1.39s/it]\u001B[A\n",
      " 36%|███▌      | 45/125 [01:01<01:51,  1.39s/it]\u001B[A\n",
      " 37%|███▋      | 46/125 [01:02<01:49,  1.39s/it]\u001B[A\n",
      " 38%|███▊      | 47/125 [01:04<01:48,  1.39s/it]\u001B[A\n",
      " 38%|███▊      | 48/125 [01:05<01:46,  1.39s/it]\u001B[AInput ids are automatically padded from 439 to 512 to be a multiple of `config.attention_window`: 512\n",
      "\n",
      " 39%|███▉      | 49/125 [01:06<01:31,  1.20s/it]\u001B[A\n",
      " 40%|████      | 50/125 [01:07<01:35,  1.27s/it]\u001B[A\n",
      " 41%|████      | 51/125 [01:09<01:36,  1.30s/it]\u001B[A\n",
      " 42%|████▏     | 52/125 [01:10<01:36,  1.32s/it]\u001B[A\n",
      " 42%|████▏     | 53/125 [01:12<01:36,  1.34s/it]\u001B[A\n",
      " 43%|████▎     | 54/125 [01:13<01:35,  1.35s/it]\u001B[A\n",
      " 44%|████▍     | 55/125 [01:14<01:35,  1.36s/it]\u001B[A\n",
      " 45%|████▍     | 56/125 [01:16<01:35,  1.38s/it]\u001B[AInput ids are automatically padded from 621 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "\n",
      " 46%|████▌     | 57/125 [01:17<01:35,  1.40s/it]\u001B[A\n",
      " 46%|████▋     | 58/125 [01:19<01:34,  1.41s/it]\u001B[A\n",
      " 47%|████▋     | 59/125 [01:20<01:33,  1.42s/it]\u001B[A\n",
      " 48%|████▊     | 60/125 [01:22<01:33,  1.43s/it]\u001B[A\n",
      " 49%|████▉     | 61/125 [01:23<01:30,  1.42s/it]\u001B[A\n",
      " 50%|████▉     | 62/125 [01:24<01:28,  1.41s/it]\u001B[A\n",
      " 50%|█████     | 63/125 [01:26<01:26,  1.40s/it]\u001B[A\n",
      " 51%|█████     | 64/125 [01:27<01:25,  1.40s/it]\u001B[A\n",
      " 52%|█████▏    | 65/125 [01:28<01:23,  1.39s/it]\u001B[A\n",
      " 53%|█████▎    | 66/125 [01:30<01:22,  1.39s/it]\u001B[A\n",
      " 54%|█████▎    | 67/125 [01:31<01:21,  1.40s/it]\u001B[A\n",
      " 54%|█████▍    | 68/125 [01:33<01:19,  1.39s/it]\u001B[A\n",
      " 55%|█████▌    | 69/125 [01:34<01:17,  1.39s/it]\u001B[A\n",
      " 56%|█████▌    | 70/125 [01:35<01:17,  1.42s/it]\u001B[A\n",
      " 57%|█████▋    | 71/125 [01:37<01:15,  1.41s/it]\u001B[A\n",
      " 58%|█████▊    | 72/125 [01:38<01:14,  1.41s/it]\u001B[A\n",
      " 58%|█████▊    | 73/125 [01:40<01:13,  1.42s/it]\u001B[A\n",
      " 59%|█████▉    | 74/125 [01:41<01:12,  1.42s/it]\u001B[A\n",
      " 60%|██████    | 75/125 [01:42<01:10,  1.40s/it]\u001B[A\n",
      " 61%|██████    | 76/125 [01:44<01:08,  1.39s/it]\u001B[A\n",
      " 62%|██████▏   | 77/125 [01:45<01:06,  1.39s/it]\u001B[A\n",
      " 62%|██████▏   | 78/125 [01:47<01:07,  1.43s/it]\u001B[A\n",
      " 63%|██████▎   | 79/125 [01:48<01:06,  1.45s/it]\u001B[A\n",
      " 64%|██████▍   | 80/125 [01:50<01:06,  1.47s/it]\u001B[A\n",
      " 65%|██████▍   | 81/125 [01:51<01:03,  1.44s/it]\u001B[A\n",
      " 66%|██████▌   | 82/125 [01:52<00:53,  1.25s/it]\u001B[A\n",
      " 66%|██████▋   | 83/125 [01:53<00:55,  1.31s/it]\u001B[AInput ids are automatically padded from 640 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "\n",
      " 67%|██████▋   | 84/125 [01:55<00:54,  1.34s/it]\u001B[A\n",
      " 68%|██████▊   | 85/125 [01:56<00:53,  1.35s/it]\u001B[A\n",
      " 69%|██████▉   | 86/125 [01:58<00:53,  1.37s/it]\u001B[A\n",
      " 70%|██████▉   | 87/125 [01:59<00:52,  1.37s/it]\u001B[A\n",
      " 70%|███████   | 88/125 [02:00<00:51,  1.39s/it]\u001B[A\n",
      " 71%|███████   | 89/125 [02:02<00:49,  1.39s/it]\u001B[A\n",
      " 72%|███████▏  | 90/125 [02:03<00:48,  1.38s/it]\u001B[A\n",
      " 73%|███████▎  | 91/125 [02:05<00:46,  1.37s/it]\u001B[A\n",
      " 74%|███████▎  | 92/125 [02:06<00:45,  1.38s/it]\u001B[A\n",
      " 74%|███████▍  | 93/125 [02:07<00:42,  1.33s/it]\u001B[A\n",
      " 75%|███████▌  | 94/125 [02:09<00:41,  1.34s/it]\u001B[A\n",
      " 76%|███████▌  | 95/125 [02:10<00:44,  1.50s/it]\u001B[A\n",
      " 77%|███████▋  | 96/125 [02:12<00:44,  1.53s/it]\u001B[A\n",
      " 78%|███████▊  | 97/125 [02:14<00:43,  1.57s/it]\u001B[A\n",
      " 78%|███████▊  | 98/125 [02:15<00:41,  1.55s/it]\u001B[A\n",
      " 79%|███████▉  | 99/125 [02:17<00:42,  1.62s/it]\u001B[A\n",
      " 80%|████████  | 100/125 [02:18<00:38,  1.55s/it]\u001B[A\n",
      " 81%|████████  | 101/125 [02:20<00:35,  1.49s/it]\u001B[A\n",
      " 82%|████████▏ | 102/125 [02:21<00:33,  1.45s/it]\u001B[A\n",
      " 82%|████████▏ | 103/125 [02:22<00:31,  1.43s/it]\u001B[A\n",
      " 83%|████████▎ | 104/125 [02:24<00:29,  1.41s/it]\u001B[A\n",
      " 84%|████████▍ | 105/125 [02:25<00:27,  1.40s/it]\u001B[A\n",
      " 85%|████████▍ | 106/125 [02:26<00:26,  1.39s/it]\u001B[A\n",
      " 86%|████████▌ | 107/125 [02:28<00:24,  1.38s/it]\u001B[AInput ids are automatically padded from 801 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "\n",
      " 86%|████████▋ | 108/125 [02:29<00:23,  1.38s/it]\u001B[A\n",
      " 87%|████████▋ | 109/125 [02:31<00:22,  1.38s/it]\u001B[A\n",
      " 88%|████████▊ | 110/125 [02:32<00:20,  1.37s/it]\u001B[A\n",
      " 89%|████████▉ | 111/125 [02:33<00:19,  1.38s/it]\u001B[A\n",
      " 90%|████████▉ | 112/125 [02:35<00:17,  1.37s/it]\u001B[A\n",
      " 90%|█████████ | 113/125 [02:36<00:16,  1.37s/it]\u001B[A\n",
      " 91%|█████████ | 114/125 [02:37<00:15,  1.38s/it]\u001B[AInput ids are automatically padded from 822 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "\n",
      " 92%|█████████▏| 115/125 [02:39<00:13,  1.38s/it]\u001B[A\n",
      " 93%|█████████▎| 116/125 [02:40<00:12,  1.38s/it]\u001B[A\n",
      " 94%|█████████▎| 117/125 [02:42<00:11,  1.38s/it]\u001B[A\n",
      " 94%|█████████▍| 118/125 [02:43<00:09,  1.37s/it]\u001B[A\n",
      " 95%|█████████▌| 119/125 [02:44<00:08,  1.37s/it]\u001B[A\n",
      " 96%|█████████▌| 120/125 [02:46<00:06,  1.37s/it]\u001B[A\n",
      " 97%|█████████▋| 121/125 [02:47<00:05,  1.37s/it]\u001B[A\n",
      " 98%|█████████▊| 122/125 [02:48<00:04,  1.38s/it]\u001B[A\n",
      " 98%|█████████▊| 123/125 [02:50<00:02,  1.37s/it]\u001B[A\n",
      " 99%|█████████▉| 124/125 [02:51<00:01,  1.37s/it]\u001B[A\n",
      "100%|██████████| 125/125 [02:53<00:00,  1.38s/it]\u001B[A\n",
      "100%|██████████| 1/1 [05:41<00:00, 341.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current auc 0.810515873015873\n",
      "Best auc 0.810515873015873\n",
      "Current auprc 0.4289431341236658\n",
      "Best auprc 0.4289431341236658\n",
      "Current f1 0.35051546391752575\n",
      "Best f1 0.35051546391752575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if args.modeltype == 'TS':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.ts_learning_rate)\n",
    "elif args.modeltype == 'Text' or args.modeltype == 'TS_Text':\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': [p for n, p in model.named_parameters() if 'bert' not in n]},\n",
    "        {'params': [p for n, p in model.named_parameters() if 'bert' in n], 'lr': args.txt_learning_rate}\n",
    "    ], lr=args.ts_learning_rate)\n",
    "else:\n",
    "    raise ValueError(\"Unknown modeltype in optimizer.\")\n",
    "\n",
    "model, optimizer, train_dataloader, val_dataloader, test_data_loader = \\\n",
    "    accelerator.prepare(model, optimizer, train_dataloader, val_dataloader, test_data_loader)\n",
    "\n",
    "trainer_irg(model=model, args=args, accelerator=accelerator, train_dataloader=train_dataloader, \\\n",
    "            dev_dataloader=val_dataloader, test_data_loader=test_data_loader, device=device, \\\n",
    "            optimizer=optimizer, writer=writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bec66f34abf3c5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "84ab0794ced7c8d7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T04:03:06.032100335Z",
     "start_time": "2024-04-14T04:00:21.821791280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run/TS_Text/ihm/TS_Text/TS_48/Atten/Text_48/bioLongformer/1024/cross_attn3/irregular_TS_64/irregular_Text_64/5e-05_2_3_0.0004_1_8_128_1_2/f1/42.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/125 [00:01<02:50,  1.38s/it]Input ids are automatically padded from 504 to 512 to be a multiple of `config.attention_window`: 512\n",
      "  2%|▏         | 3/125 [00:03<02:21,  1.16s/it]Input ids are automatically padded from 681 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "  5%|▍         | 6/125 [00:07<02:34,  1.30s/it]Input ids are automatically padded from 788 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "  6%|▌         | 7/125 [00:08<02:34,  1.31s/it]Input ids are automatically padded from 794 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "  6%|▋         | 8/125 [00:10<02:35,  1.33s/it]Input ids are automatically padded from 770 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "  7%|▋         | 9/125 [00:11<02:34,  1.33s/it]Input ids are automatically padded from 817 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 10%|▉         | 12/125 [00:15<02:31,  1.34s/it]Input ids are automatically padded from 606 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 10%|█         | 13/125 [00:16<02:29,  1.34s/it]Input ids are automatically padded from 813 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 13%|█▎        | 16/125 [00:20<02:26,  1.34s/it]Input ids are automatically padded from 779 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 14%|█▍        | 18/125 [00:23<02:23,  1.34s/it]Input ids are automatically padded from 732 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 16%|█▌        | 20/125 [00:26<02:21,  1.34s/it]Input ids are automatically padded from 841 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 17%|█▋        | 21/125 [00:27<02:19,  1.34s/it]Input ids are automatically padded from 494 to 512 to be a multiple of `config.attention_window`: 512\n",
      " 21%|██        | 26/125 [00:33<02:08,  1.30s/it]Input ids are automatically padded from 1020 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 22%|██▏       | 27/125 [00:35<02:09,  1.32s/it]Input ids are automatically padded from 807 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 24%|██▍       | 30/125 [00:39<02:07,  1.34s/it]Input ids are automatically padded from 701 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 27%|██▋       | 34/125 [00:44<02:02,  1.35s/it]Input ids are automatically padded from 915 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 28%|██▊       | 35/125 [00:45<02:01,  1.35s/it]Input ids are automatically padded from 746 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 29%|██▉       | 36/125 [00:47<02:00,  1.35s/it]Input ids are automatically padded from 623 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 30%|███       | 38/125 [00:50<01:57,  1.34s/it]Input ids are automatically padded from 691 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 33%|███▎      | 41/125 [00:54<01:52,  1.35s/it]Input ids are automatically padded from 711 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 37%|███▋      | 46/125 [01:00<01:46,  1.34s/it]Input ids are automatically padded from 797 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 39%|███▉      | 49/125 [01:04<01:42,  1.35s/it]Input ids are automatically padded from 743 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 40%|████      | 50/125 [01:06<01:41,  1.35s/it]Input ids are automatically padded from 657 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 44%|████▍     | 55/125 [01:12<01:34,  1.35s/it]Input ids are automatically padded from 820 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 45%|████▍     | 56/125 [01:14<01:32,  1.35s/it]Input ids are automatically padded from 633 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 46%|████▋     | 58/125 [01:17<01:31,  1.36s/it]Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 47%|████▋     | 59/125 [01:18<01:29,  1.36s/it]Input ids are automatically padded from 823 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 48%|████▊     | 60/125 [01:19<01:28,  1.36s/it]Input ids are automatically padded from 939 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 51%|█████     | 64/125 [01:25<01:21,  1.34s/it]Input ids are automatically padded from 956 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 52%|█████▏    | 65/125 [01:26<01:20,  1.34s/it]Input ids are automatically padded from 866 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 55%|█████▌    | 69/125 [01:31<01:15,  1.35s/it]Input ids are automatically padded from 649 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 62%|██████▏   | 77/125 [01:41<01:03,  1.32s/it]Input ids are automatically padded from 639 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 66%|██████▋   | 83/125 [01:49<00:52,  1.25s/it]Input ids are automatically padded from 703 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 67%|██████▋   | 84/125 [01:50<00:52,  1.28s/it]Input ids are automatically padded from 668 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 68%|██████▊   | 85/125 [01:51<00:52,  1.30s/it]Input ids are automatically padded from 671 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 70%|██████▉   | 87/125 [01:54<00:50,  1.32s/it]Input ids are automatically padded from 815 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 70%|███████   | 88/125 [01:56<00:49,  1.33s/it]Input ids are automatically padded from 478 to 512 to be a multiple of `config.attention_window`: 512\n",
      " 71%|███████   | 89/125 [01:56<00:41,  1.15s/it]Input ids are automatically padded from 622 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 74%|███████▍  | 93/125 [02:01<00:38,  1.22s/it]Input ids are automatically padded from 847 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 75%|███████▌  | 94/125 [02:02<00:38,  1.25s/it]Input ids are automatically padded from 562 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 76%|███████▌  | 95/125 [02:04<00:38,  1.28s/it]Input ids are automatically padded from 695 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 78%|███████▊  | 97/125 [02:06<00:36,  1.31s/it]Input ids are automatically padded from 654 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 79%|███████▉  | 99/125 [02:09<00:34,  1.33s/it]Input ids are automatically padded from 869 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 80%|████████  | 100/125 [02:10<00:33,  1.33s/it]Input ids are automatically padded from 517 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 81%|████████  | 101/125 [02:12<00:32,  1.33s/it]Input ids are automatically padded from 750 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 83%|████████▎ | 104/125 [02:16<00:28,  1.34s/it]Input ids are automatically padded from 773 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 84%|████████▍ | 105/125 [02:17<00:26,  1.34s/it]Input ids are automatically padded from 715 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 89%|████████▉ | 111/125 [02:25<00:18,  1.34s/it]Input ids are automatically padded from 902 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 91%|█████████ | 114/125 [02:29<00:14,  1.35s/it]Input ids are automatically padded from 597 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 92%|█████████▏| 115/125 [02:31<00:13,  1.35s/it]Input ids are automatically padded from 630 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 93%|█████████▎| 116/125 [02:32<00:12,  1.35s/it]Input ids are automatically padded from 572 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 95%|█████████▌| 119/125 [02:36<00:08,  1.34s/it]Input ids are automatically padded from 546 to 1024 to be a multiple of `config.attention_window`: 512\n",
      " 96%|█████████▌| 120/125 [02:37<00:06,  1.34s/it]Input ids are automatically padded from 670 to 1024 to be a multiple of `config.attention_window`: 512\n",
      "100%|██████████| 125/125 [02:43<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_test(args, model, test_data_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6425b8566db17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load evaluation result\n",
    "\n",
    "the performance of proposed methods and baselines are measured by the F1, AUPR, and AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ea38aee8aebeaf7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T04:03:06.036335315Z",
     "start_time": "2024-04-14T04:03:06.031806250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{42: {'auc': {'val': 0.810515873015873, 'test': 0.7829927425515661}, 'auprc': {'val': 0.4289431341236658, 'test': 0.3553091706855146}, 'f1': {'val': 0.35051546391752575, 'test': 0.2608695652173913}}}\n"
     ]
    }
   ],
   "source": [
    "for result_file in os.listdir(args.ck_file_path):\n",
    "    if 'result.pkl' in result_file:\n",
    "        eval_result_path = args.ck_file_path + result_file\n",
    "        # print(eval_result_path)\n",
    "        with open(eval_result_path,'rb') as f:\n",
    "            evaluation_result = pickle.load(f)\n",
    "            print(evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f98a4705268e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Since for the demonstration we only used 1000 sample for 1 epoch, and we fill in dummy data for entry with missing value, we could not achieve the same result as the paper describe.\n",
    "\n",
    "We plan to further furnish the code and run on the full sample data with more epoch, to see if we could get the result as the paper describe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
