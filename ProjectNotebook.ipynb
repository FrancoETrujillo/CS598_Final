{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f954d686b0a84023",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Improving Medical Predictions by Irregular Multimodal Electronic Health Records Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d2cda9f6d05930",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Team and Repo\n",
    "## Team Members:\n",
    "- Franco E.Trujillo - fet2@illinois.edu\n",
    "- Hongyi Wu - hongyiw6@illinois.edu\n",
    "\n",
    "## Project Repo:\n",
    "- [https://github.com/FrancoETrujillo/CS598_Final](https://github.com/FrancoETrujillo/CS598_Final)\n",
    "\n",
    "## Reference Repos:\n",
    "- [https://github.com/XZhang97666/MultimodalMIMIC](https://github.com/XZhang97666/MultimodalMIMIC)\n",
    "    - commit hash used: 8e513ca\n",
    "- [https://github.com/YerevaNN/mimic3-benchmarks](https://github.com/YerevaNN/mimic3-benchmarks)\n",
    "    - commit hash used: ea0314c\n",
    "- [https://github.com/kaggarwal/ClinicalNotesICU](https://github.com/kaggarwal/ClinicalNotesICU)\n",
    "    - commit hash used: 9c2b740"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b40d117099b4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Introduction\n",
    "This paper intends to address the challenges of handling irregularity and the integration of multimodal data for medical prediction tasks.\n",
    "\n",
    "## Background of the problem\n",
    "### What type of problem:\n",
    "The paper focuses on 2 main problems; Mortality Prediction and Phenotype Classification\n",
    "### What is the importance/meaning of solving the problem: \n",
    "ICUs admit patients with life-threatening conditions, Improving the efficacy and efficiency of predictions by accounting for irregular data in EHRs can help the medical providers to make more accurate and quick decisions that could save lives.\n",
    "\n",
    "### What is the difficulty of the problem:\n",
    "The primary difficulty is the handling the irregular sampling of data and the effective integration and modeling of EHR records like numerical time series and textual notes taken in multiple points in time and frequencies.\n",
    "\n",
    "![EHR sample image](.img/sample_ehr.png)\n",
    "\n",
    "### The state-of-the-art methods and effectiveness.\n",
    "For irregular data handling;\n",
    "> [1] Lipton, Z. C., Kale, D., and Wetzel, R. Directly modeling\n",
    "> missing data in sequences with rnns: Improved classification of clinical time series. In Machine learning for\n",
    "> healthcare conference, pp. 253–270. PMLR, 2016.\n",
    "\n",
    "> [2] Shukla, S. N. and Marlin, B. M. Multi-time attention networks for irregularly sampled time series. arXiv preprint\n",
    "> arXiv:2101.10318, 2021.\n",
    "\n",
    "For irregular clinical notes processing;\n",
    "> [3] Golmaei, S. N. and Luo, X. Deepnote-gnn: predicting hospital readmission using clinical notes and patient network.\n",
    "> In Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics,\n",
    "> pp. 1–9, 2021.\n",
    "\n",
    "> [4]Mahbub, M., Srinivasan, S., Danciu, I., Peluso, A., Begoli, E., Tamang, S., and Peterson, G. D. \n",
    "> Unstructured clinical notes within the 24 hours since admission predict short,> mid & long-term mortality in adult icu patients. \n",
    "> Plos one, 17(1):e0262182, 2022.\n",
    "\n",
    "## Paper explanation\n",
    "### What did the paper propose\n",
    "The general problem addressed in this paper is to find a better approach to handling irregular multimodal data obtained on EHRs to better assess real-time predictions in ICUs. \n",
    "\n",
    "### What is the innovations of the method\n",
    "To better approach irregularity and multi-modal data the paper proposes integrating the real-time series and clinical notes while considering their irregularities. This by doing the following:\n",
    "\n",
    "![High level arch](.img/high_arch_w_desc.png)\n",
    "\n",
    "#### Modeling Irregularity in Time Series:\n",
    "1. Temporal Discretization-Based Embeddings (TDE): Utilizes a novel unified\n",
    "approach (UTDE) that combines:\n",
    "    - Imputation: Regularizes time series by filling in missing values based\n",
    "on prior observations or statistical methods.\n",
    "    - Discretized Multi-Time Attention (mTAND): Applies a learned\n",
    "interpolation method using a multi-time attention mechanism to\n",
    "represent the irregular time series data better.\n",
    "2. Unified Approach (UTDE): This approach integrates imputation and mTAND\n",
    "through a gating mechanism to dynamically combine the representation of\n",
    "the time series.\n",
    " \n",
    " ![Detail arch](.img/imputation_plus_mtand.png)\n",
    "\n",
    "#### Processing Irregular Clinical Notes:\n",
    "1. Text Encoding: Uses a pretrained model (TextEncoder) to encode clinical\n",
    "notes into a series of representations.\n",
    "2. Irregularity Modeling: Sorts these representations by time, treats them as\n",
    "Multivariate Irregularly Sampled Time Series (MINSTS), and employs mTAND\n",
    "to generate a set of text interpolation representations to handle irregularities.\n",
    "\n",
    "\n",
    "#### Multimodal Fusion:\n",
    "1. Interleaved Attention Mechanism: Fuses time series and clinical note\n",
    "representations across temporal steps, integrating irregularity into multimodal\n",
    "representations.\n",
    "2. Self and Cross-Attention:\n",
    "    - Multi-Head Self-Attention (MH): Acquires contextual embeddings for\n",
    "each modality by focusing within the same modality across time.\n",
    "    - Multi-Head Cross-Attention (CMH): Each modality learns from the\n",
    "other, integrating information across modalities.\n",
    "3. Feed-Forward and Prediction Layers: A feed-forward sublayer follows the\n",
    "CMH outputs, with layer normalization and residual connections applied. The\n",
    "final step involves passing the integrated representations through fully\n",
    "connected layers to predict the outcome.\n",
    "\n",
    "\n",
    "### How well the proposed method work (in its own metrics)\n",
    " The proposed methods for two medical prediction tasks consistently outperforms state-ofthe-art (SOTA) baselines in each single modality and multimodal fusion scenarios. \n",
    "Observing a relative improvements of 6.5%, 3.6%, and 4.3% in F1 for time series, clinical notes, and multimodal fusion, respectively. \n",
    "\n",
    "### What is the contribution to the reasearch regime (referring the Background above, how important the paper is to the problem).\n",
    "The paper's contribution is important because it provides a new direction for EHR-based predictive models to consider time irregularity that could lead to more accurate and reliable medical predictions, helping patients and healthcare processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091ff27ef282204",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Scope of Reproducibility:\n",
    "\n",
    "For our project we plan to reproduce the experiment with In Hospital Mortality (IHM). And prove the following hypotheses:\n",
    "\n",
    "\n",
    "1. The inclusion of UTDE improves the performance of the model.\n",
    "2. Considering irregularities in clinical note embedding improves the performance of the model.\n",
    "3. The introduction of UTDE and mTAND for processing time series and clinical notes, respectively, plus the integration of Multimodal fusion outperforms F1 score against standard baselines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaf5f852216c24d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prerequisites to Reproduce the project\n",
    "- Get access to the MIMIC dataset\n",
    "- Modify the GlobalConfigs.py to use your own project and data paths\n",
    "- Install the required dependencies listed on Requirements.txt, we recommend using Conda with python 3.11\n",
    "- Modify the directory variables on the **Configuring imports and directories** section bellow if needed\n",
    "\n",
    "**Notes:** \n",
    "\n",
    "- We are unable to share the preprocess pkl files due to the [MIMIC DUA](https://physionet.org/content/mimiciii/view-dua/1.4/)\n",
    "- This project has being developed and tested using Linux Mint 21.2, ubuntu variants should work, but you may need to modify it to execute on another OS\n",
    "- More information about our dir structure can be found on our README.md \n",
    "- For this project we've used an NVDIA 4070 GPU with a limited dataset, you may need more resources for your case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d958f689e7c76",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Methodology\n",
    "\n",
    "The project reproduction consists on the following sections\n",
    "- Data\n",
    "- Models\n",
    "- Training\n",
    "- Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fccbbee93bdeb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data\n",
    "\n",
    "This paper uses the MIMICIII dataset as starting point to obtain timeseries information and medical notes. \n",
    "\n",
    "The MIMIC-III dataset is composed of a set of CSV files containing information about patients, their stays, events, and notes. \n",
    "\n",
    "For our project the most relevant tables are:\n",
    "### ADMISSIONS\n",
    "Contains information about the admissions of patients to the hospital.\n",
    "\n",
    "![Admissions](.img/Addmissions_table.png)\n",
    "\n",
    "\n",
    "### PATIENTS\n",
    "Contains information about the patients.\n",
    "\n",
    "![Patients](.img/patients_table.png)\n",
    "\n",
    "\n",
    "### ICUSTAYS\n",
    "Contains information about the ICU stays of patients.\n",
    "\n",
    "![ICUStays](.img/icu_stays_table.png)\n",
    "\n",
    "\n",
    "### NOTEEVENTS\n",
    "Contains information about the notes taken for each patient.\n",
    "\n",
    "![NoteEvents](.img/NoteEvents_table.png)\n",
    "\n",
    "\n",
    "### CALLOUT\n",
    "Contains information about when patients were ready for discharge (called out), and the actual time of their discharge (or more generally, their outcome).\n",
    "\n",
    "![Callout](.img/callout_table.png)\n",
    "\n",
    "\n",
    "More info about the table structures can be found at [https://mit-lcp.github.io/mimic-schema-spy/index.html](https://mit-lcp.github.io/mimic-schema-spy/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea0197a327d87e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    " \n",
    "## Getting the data\n",
    " The following code contains some useful code to download and extract the dataset files locally\n",
    " \n",
    "**Note**: To download the mimic dataset is necessary to complete the request for access at [Physionet](https://physionet.org/)\n",
    "\n",
    "After downloading and extracting the dataset, we will have a directory structure like this:\n",
    ".\n",
    "├── ClinicalNotesICU\n",
    "│   ├── models\n",
    "│   └── scripts\n",
    "├── mimic3-benchmarks\n",
    "│   ├── data\n",
    "│   │   ├── decompensation\n",
    "│   │   ├── in-hospital-mortality\n",
    "│   │   ├── length-of-stay\n",
    "│   │   ├── multitask\n",
    "│   │   ├── phenotyping\n",
    "│   │   └── root\n",
    "│   │       ├── test_text_fixed\n",
    "│   │       └── text_fixed\n",
    "│   ├── mimic3benchmark\n",
    "│   │   ├── evaluation\n",
    "│   │   ├── resources\n",
    "│   │   ├── scripts\n",
    "│   │   └── tests\n",
    "│   │       └── resources\n",
    "│   └── mimic3models\n",
    "│       ├── decompensation\n",
    "│       │   └── logistic\n",
    "│       ├── in_hospital_mortality\n",
    "│       │   └── logistic\n",
    "│       ├── keras_models\n",
    "│       ├── length_of_stay\n",
    "│       │   └── logistic\n",
    "│       ├── multitask\n",
    "│       ├── phenotyping\n",
    "│       │   └── logistic\n",
    "│       └── resources\n",
    "└── MultimodalMIMIC\n",
    "    ├── Data\n",
    "    │   ├── ihm\n",
    "    │   └── irregular\n",
    "    └── run\n",
    "        └── TS_Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55643c225c7bfa5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Config tasks to execute\n",
    "Open and edit GlobalConfigs.py to set up the local path to the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9e41a54007f74873",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.344703746Z",
     "start_time": "2024-04-28T04:15:54.178356445Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "# Imports and configs\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "from GlobalConfigs import *\n",
    "\n",
    "DOWNLOAD_DATASET = False\n",
    "EXTRACT_COMPRESSED_CSVS = False\n",
    "PREPROCESS_BENCHMARKS = False\n",
    "PREPROCESS_CLINICAL_NOTES = False\n",
    "PREPROCESS_MULTIMODAL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b9290b2ec9b76",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd912cb01d3abcc0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.358723222Z",
     "start_time": "2024-04-28T04:15:54.337267193Z"
    }
   },
   "outputs": [],
   "source": [
    "# change physionet_username to your username\n",
    "if DOWNLOAD_DATASET:\n",
    "\n",
    "    physionet_username = \"your_user_name\"\n",
    "    password = \"your_pass\"\n",
    "    destination_directory = \"data/MIMICIII_Original\"\n",
    "\n",
    "    command = [\n",
    "        \"wget\", \"-r\", \"-N\", \"-c\", \"-np\",\n",
    "        \"--user\", physionet_username,\n",
    "        \"--password\", password,\n",
    "        \"https://physionet.org/files/mimiciii/1.4/\",\n",
    "        \"-P\", destination_directory\n",
    "    ]\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Command failed with return code {process.returncode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7b7101051b10d00a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.419562337Z",
     "start_time": "2024-04-28T04:15:54.361246911Z"
    }
   },
   "outputs": [],
   "source": [
    "if EXTRACT_COMPRESSED_CSVS:\n",
    "    command = ['./decompress_mimic.sh', '-d', 'data/MIMICIII_Original/physionet.org/files/mimiciii/1.4/', '-o',\n",
    "               'data/mimic3']\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Command failed with return code {process.returncode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee902ed9e8ef43",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preparing the data\n",
    "The original paper leverages the following projects to help on the data preparation and extraction from the original MIMIC CSVs\n",
    "\n",
    "It leverages the **mimic3-benchmarks** and the **ClinicalNotesICU** for the following:\n",
    "\n",
    "- Cleanup invalid data\n",
    "- Map the events, diagnoses, and stays for each patient.\n",
    "- Extract timeseries for in-hospital-mortality \n",
    "- Split timeseries data into train and test sets\n",
    "- Extract Medical notes for patients\n",
    "- Split Medical notes for train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63cceb7ae9be99",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### MIMIC benchmarks\n",
    "Helps to process timeseries data and divide train and test sets\n",
    "[mimic3-benchmarks](https://github.com/YerevaNN/mimic3-benchmarks.git)\n",
    "\n",
    "This repo contains a set of scripts that take the RAW mimic CSVs and prepare the irregular data:\n",
    "- extract_subjects.py:\n",
    "Generates one directory per SUBJECT_ID and writes ICU stay information to data/{SUBJECT_ID}/stays.csv, diagnoses to data/{SUBJECT_ID}/diagnoses.csv, and events to data/{SUBJECT_ID}/events.csv\n",
    "\n",
    "\n",
    "- validate_events.py\n",
    "Attempts to fix some issues (ICU stay ID is missing) and removes the events that have missing information. About 80% of events remain after removing all suspicious rows\n",
    "\n",
    "\n",
    "- extract_episodes_from_subjects.py\n",
    "Breaks up per-subject data into separate episodes (pertaining to ICU stays). Time series of events are stored in {SUBJECT_ID}/episode{#}_timeseries.csv (where # counts distinct episodes) while episode-level information (patient age, gender, ethnicity, height, weight) and outcomes (mortality, length of stay, diagnoses) are stores in {SUBJECT_ID}/episode{#}.csv. This script requires two files, one that maps event ITEMIDs to clinical variables and another that defines valid ranges for clinical variables\n",
    "\n",
    "\n",
    "- split_train_and_test.py\n",
    "Splits the whole dataset into training and testing sets.\n",
    "\n",
    "\n",
    "- create_in_hospital_mortality.py\n",
    "Generate task-specific datasets for in-hospital-mortality prediction\n",
    "\n",
    "After running the preparation scripts we end up with a directory data/in-hospital-mortality we have two subdirectories: train and test. Each of them contains a bunch of ICU stays and one file with name listfile.csv, which lists all samples in that particular set. Each row of listfile.csv has the following form: icu_stay, period_length, label(s). A row specifies a sample for which the input is the collection of ICU event of icu_stay that occurred in the first period_length hours of the stay and the target are label(s). In in-hospital mortality prediction task period_length is always 48 hours.\n",
    "\n",
    "\n",
    "The project does not work out of the box, so we downloaded the sourcecode and modify it inside this repo under the [mimic3-benchmarks](./mimic3-benchmarks) folder\n",
    "To simplify the process we have created the following script `./build_benchmark_data.sh` to run all timeseries required tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "572e454792dbbde4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.459243594Z",
     "start_time": "2024-04-28T04:15:54.413721292Z"
    }
   },
   "outputs": [],
   "source": [
    "if PREPROCESS_BENCHMARKS:\n",
    "    command = [\"./build_benchmark_data.sh\"]\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, shell=True)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Command failed with return code {process.returncode}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f45bd0bc84d872",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### ClinicalNotesICU\n",
    "Helps to process medical notes and divide in train and test\n",
    " [ClinicalNotesICU](https://github.com/kaggarwal/ClinicalNotesICU.git)\n",
    "\n",
    "Similar to the mimic3-benchmarks, this repo contains a set of scripts that take the RAW mimic CSVs and process the clinical notes for the previously generated train and test datasets.\n",
    "\n",
    "- extract_notes.py\n",
    "Uses the NOTEEVENTS.csv and the previously generated train and test sets to extract the notes within the first 48 hours of the event and saves them on its own train a test data directories \n",
    "\n",
    "- extract_T0.py\n",
    "Uses the stays.csv and events.csv to extract the episodes start time and save them into a binary pkl file.\n",
    "\n",
    "The project does not work out of the box, so we downloaded the sourcecode and modify it inside this repo under the [ClinicalNotesICU](./ClinicalNotesICU) folder\n",
    "\n",
    "To simplify the process we have created the following script `./extract_med_notes.sh` tu run all the required tasks for clinical notes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d23722350fecd73f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.475779986Z",
     "start_time": "2024-04-28T04:15:54.450344092Z"
    }
   },
   "outputs": [],
   "source": [
    "if PREPROCESS_CLINICAL_NOTES:\n",
    "    command = [\"./extract_med_notes.sh\"]\n",
    "\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, shell=True)\n",
    "\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "    process.wait()\n",
    "\n",
    "    if process.returncode != 0:\n",
    "        print(f\"Command failed with return code {process.returncode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839edc8722b2b0e5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Preprocess time series For Mimic Multimodal \n",
    "The next step is to discretize and normalize the timeseries data, as well as link the clinical notes with their corresponding timestamps.\n",
    "\n",
    "The [paper's repo](https://github.com/XZhang97666/MultimodalMIMIC.git) provides a preprocessing script to work on this task.\n",
    "\n",
    "After running the preprocessing steps we save the following PKLs to be used by the model: \n",
    "```\n",
    "mean_std.pkl \n",
    "norm_ts_test.pkl\n",
    "norm_ts_train.pkl\n",
    "norm_ts_val.pkl\n",
    "testp2x_data.pkl\n",
    "trainp2x_data.pkl\n",
    "ts_test.pkl\n",
    "ts_train.pkl\n",
    "ts_val.pkl\n",
    "valp2x_data.pkl\n",
    "```\n",
    "The project does not work out of the box, so we used it partially to call some of the functions from this notebook; the downloaded sourcecode and modifications are inside this repo under the [MultimodalMIMIC](./MultimodalMIMIC) folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d88a4406872a51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Configuring imports and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a09559d5533221a4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.505043429Z",
     "start_time": "2024-04-28T04:15:54.474898444Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# Define ExperimentClass\n",
    "@dataclass\n",
    "class ModelExperiment:\n",
    "    tag: str\n",
    "    epochs: int = 1\n",
    "    max_text_length: int = 512\n",
    "    n_samples: Optional[int] = 500  # None for full dataset\n",
    "    imputation: str = \"previous\"  # 'zero', 'normal_value', 'previous', 'next'\n",
    "    training_time_millis: Optional[int] = None\n",
    "    eval_auc_results: Optional[dict] = None\n",
    "    eval_f1_results: Optional[dict] = None\n",
    "    eval_auprc_results: Optional[dict] = None\n",
    "\n",
    "\n",
    "experiment1e1000sP = ModelExperiment(tag=\"experiment1e1000sP\", epochs=1, n_samples=1000, imputation=\"previous\")\n",
    "experiment3e1000sP = ModelExperiment(tag=\"experiment3e1000sP\", epochs=3, n_samples=1000, imputation=\"previous\")\n",
    "experiment6e1000sP = ModelExperiment(tag=\"experiment6e1000sP\", epochs=6, n_samples=1000, imputation=\"previous\")\n",
    "experiment1e3000sP = ModelExperiment(tag=\"experiment1e3000sP\", epochs=1, n_samples=3000, imputation=\"previous\")\n",
    "experiment3e3000sP = ModelExperiment(tag=\"experiment3e3000sP\", epochs=3, n_samples=3000, imputation=\"previous\")\n",
    "experiment6e3000sP = ModelExperiment(tag=\"experiment6e3000sP\", epochs=6, n_samples=3000, imputation=\"previous\")\n",
    "experiment1eFullP = ModelExperiment(tag=\"experiment1eFullP\", epochs=1, n_samples=None, imputation=\"previous\")\n",
    "experiment6eFullP = ModelExperiment(tag=\"experiment6eFullP\", epochs=6, n_samples=None, imputation=\"previous\")\n",
    "experiment3e3000sZ = ModelExperiment(tag=\"experiment6e3000sZ\", epochs=3, n_samples=3000, imputation=\"zero\")\n",
    "experiment6e1000sZ = ModelExperiment(tag=\"experiment6e1000sZ\", epochs=6, n_samples=1000, imputation=\"zero\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "1ed034beed47eeaf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.521182512Z",
     "start_time": "2024-04-28T04:15:54.504613889Z"
    }
   },
   "outputs": [],
   "source": [
    "from mimic3benchmark.readers import InHospitalMortalityReader\n",
    "from MultimodalMIMIC.preprocessing import Discretizer_multi\n",
    "from typing import Optional, Any\n",
    "from readers import Reader\n",
    "import gzip\n",
    "from mimic3models.preprocessing import Normalizer\n",
    "from MultimodalMIMIC.preprocessing import extract_irregular\n",
    "from MultimodalMIMIC.preprocessing import mean_std\n",
    "from MultimodalMIMIC.preprocessing import normalize\n",
    "from MultimodalMIMIC.text_utils import TextReader\n",
    "from MultimodalMIMIC.preprocessing import merge_text_ts\n",
    "\n",
    "GENERATE_PREPROCESSED_PKL = True\n",
    "\n",
    "# Paths for data\n",
    "ihm_data_path = f\"{BENCHMARKS_ROOT_PATH}/data/in-hospital-mortality\"\n",
    "ihm_train_data_path = f\"{ihm_data_path}/train\"\n",
    "ihm_test_data_path = f\"{ihm_data_path}/test\"\n",
    "discretizer_config_path = f\"{MULTI_MODAL_MIMIC_PATH}/Data/irregular/discretizer_config.json\"\n",
    "channel_info_path = f\"{MULTI_MODAL_MIMIC_PATH}/Data/irregular/channel_info.json\"\n",
    "textdata_fixed = f\"{BENCHMARKS_ROOT_PATH}/data/root/text_fixed/train/\"\n",
    "text_start_time_path = f\"{BENCHMARKS_ROOT_PATH}/data/root/text_fixed/starttime.pkl\"\n",
    "test_textdata_fixed = f\"{BENCHMARKS_ROOT_PATH}/data/root/text_fixed/test/\"\n",
    "test_text_start_time_path = f\"{BENCHMARKS_ROOT_PATH}/data/root/text_fixed/test_starttime.pkl\"\n",
    "\n",
    "current_experiment = experiment1e1000sP\n",
    "sample_postfix = str(current_experiment.n_samples) if current_experiment.n_samples else \"Full\"\n",
    "ihm_discrete_save_path = f\"{MULTI_MODAL_MIMIC_PATH}/Data/ihm_{sample_postfix}_{current_experiment.imputation}\"\n",
    "\n",
    "# Modify this to take only a subset of the full data; None takes the full data\n",
    "n_samples_elements = current_experiment.n_samples\n",
    "\n",
    "mortality_period = 48\n",
    "timestep = 1.0\n",
    "imputation = \"previous\"\n",
    "dataset_types = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "normalizer_state_file_path = f'{BENCHMARKS_ROOT_PATH}/mimic3models/in_hospital_mortality/ihm_ts{timestep}.input_str-previous.start_time-zero.normalizer'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972d061613ed073",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Reading the data\n",
    "First define the InHospitalMortalityReader to help us easily access the split datasets generated by mimic3-benchmarks. It provides helper functions to read multiple data series samples and labels by patient and map to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2f0db8b42d1f1ab5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.568714523Z",
     "start_time": "2024-04-28T04:15:54.513982916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/mimic3-benchmarks/data/in-hospital-mortality/train\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    print(ihm_train_data_path)\n",
    "    train_reader = InHospitalMortalityReader(dataset_dir=ihm_train_data_path,\n",
    "                                             listfile=os.path.join(ihm_train_data_path, 'listfile.csv'),\n",
    "                                             period_length=mortality_period)\n",
    "    val_reader = InHospitalMortalityReader(dataset_dir=ihm_train_data_path,\n",
    "                                           listfile=os.path.join(ihm_train_data_path, 'listfile.csv'),\n",
    "                                           period_length=mortality_period)\n",
    "\n",
    "    test_reader = InHospitalMortalityReader(dataset_dir=ihm_test_data_path,\n",
    "                                            listfile=os.path.join(ihm_test_data_path, 'listfile.csv'),\n",
    "                                            period_length=mortality_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e05696cbeab2d89a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:15:54.574855753Z",
     "start_time": "2024-04-28T04:15:54.554029792Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_compressed_pkl_gz(data_to_dump: Any, save_name: str):\n",
    "    print(\"saving and compressing:\", save_name)\n",
    "    with gzip.open(f'{save_name}.pkl.gz', 'wb') as file:\n",
    "        pickle.dump(data_to_dump, file)\n",
    "\n",
    "\n",
    "def load_compressed_pkl(full_file_name: str) -> Any:\n",
    "    with gzip.open(full_file_name, 'rb') as file:\n",
    "        data_loaded = pickle.load(file)\n",
    "    return data_loaded\n",
    "\n",
    "\n",
    "def read_chunk(reader, chunk_size):\n",
    "    chunk_data = {}\n",
    "    for _ in tqdm(range(chunk_size), desc=\"reading data\"):\n",
    "        ret = reader.read_next()\n",
    "        for k, v in ret.items():\n",
    "            if k not in chunk_data:\n",
    "                chunk_data[k] = []\n",
    "            chunk_data[k].append(v)\n",
    "    chunk_data[\"header\"] = chunk_data[\"header\"][0]\n",
    "    return chunk_data\n",
    "\n",
    "\n",
    "def discretize_and_save_data(reader: Reader, discretizer: Discretizer_multi, save_path: str,\n",
    "                             partial_n_samples: Optional[int] = None, save_name=str, compress_pkl: bool = False):\n",
    "    n_samples = reader.get_number_of_examples()\n",
    "    if partial_n_samples:\n",
    "        n_samples = partial_n_samples\n",
    "    ret = read_chunk(reader, n_samples)\n",
    "    irg_data = ret[\"X\"]\n",
    "    ts = ret[\"t\"]\n",
    "    labels = ret[\"y\"]\n",
    "    discrete_names = ret[\"name\"]\n",
    "\n",
    "    reg_data = []\n",
    "    for X, t in tqdm(zip(irg_data, ts), total=len(irg_data), desc=f\"discretizing data \"):\n",
    "        transformed_data = discretizer.transform(X, end=t)[0]\n",
    "        reg_data.append(transformed_data)\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    save_full_path = f\"{save_path}/{save_name}\"\n",
    "    if compress_pkl:\n",
    "        save_compressed_pkl_gz((irg_data, reg_data, labels, discrete_names), save_full_path)\n",
    "    else:\n",
    "        print(\"Saving\", f\"{save_full_path}.pkl\")\n",
    "        with open(f\"{save_full_path}.pkl\", 'wb') as file:\n",
    "            pickle.dump((irg_data, reg_data, labels, discrete_names), file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba45dd4edd24c95",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Discretize temporal data and add imputation\n",
    "\n",
    "In order to create the embeddings for the proposed model first we need to discretize and add the imputation to the missing values. In our case we will use imputation using the previous value of the series.\n",
    "\n",
    "The Discretizer_multi takes care of transforming the irregular data into samples at each timestep while filling the missing data with the desired imputation strategy considering all time based features.\n",
    "\n",
    "![Discretizer image](.img/only_discretize.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e5be5a812eb8f9ec",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:05.039268759Z",
     "start_time": "2024-04-28T04:15:54.554159287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discretize and save train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data: 100%|██████████| 1000/1000 [00:00<00:00, 1225.82it/s]\n",
      "discretizing data : 100%|██████████| 1000/1000 [00:02<00:00, 399.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/ts_train.pkl\n",
      "discretize and save val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data: 100%|██████████| 1000/1000 [00:00<00:00, 1444.67it/s]\n",
      "discretizing data : 100%|██████████| 1000/1000 [00:02<00:00, 492.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/ts_val.pkl\n",
      "discretize and save test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading data: 100%|██████████| 1000/1000 [00:00<00:00, 1685.00it/s]\n",
      "discretizing data : 100%|██████████| 1000/1000 [00:01<00:00, 565.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/ts_test.pkl\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    discretizer_multi = Discretizer_multi(\n",
    "        impute_strategy=current_experiment.imputation,\n",
    "        store_masks=True,\n",
    "        start_time='zero',\n",
    "        config_path=discretizer_config_path,\n",
    "        channel_path=channel_info_path\n",
    "    )\n",
    "    discretizer_header = discretizer_multi.transform(train_reader.read_example(0)[\"X\"])[1].split(',')\n",
    "    cont_channels = [i for (i, x) in enumerate(discretizer_header) if x.find(\"->\") == -1]\n",
    "\n",
    "    print(\"discretize and save train\")\n",
    "    discretize_and_save_data(train_reader, discretizer_multi, ihm_discrete_save_path, n_samples_elements, \"ts_train\")\n",
    "    print(\"discretize and save val\")\n",
    "    discretize_and_save_data(val_reader, discretizer_multi, ihm_discrete_save_path, n_samples_elements, \"ts_val\")\n",
    "    print(\"discretize and save test\")\n",
    "    discretize_and_save_data(test_reader, discretizer_multi, ihm_discrete_save_path, n_samples_elements, \"ts_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f129af1f21d395",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Paddings and masks\n",
    "After discretize we need to apply paddings and create masks for all features. For this we can use the function extract_irregular from MultimodalMimic. It creates the padded irregular and mask arrays and save them for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "72092e5bc118117e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:08.834728952Z",
     "start_time": "2024-04-28T04:16:05.042304353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train irregular data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/ts_train.pkl\n",
      "Extracting val irregular data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/ts_val.pkl\n",
      "Extracting test irregular data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/ts_test.pkl\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    for dataset_type in dataset_types:\n",
    "        print(f\"Extracting {dataset_type} irregular data\", flush=True)\n",
    "        in_extract_data_path = f\"{ihm_discrete_save_path}/ts_{dataset_type}.pkl\"\n",
    "        out_extract_data_path = f\"{ihm_discrete_save_path}/ts_{dataset_type}.pkl\"\n",
    "        extract_irregular(in_extract_data_path, out_extract_data_path, channel_info_path, discretizer_config_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "acce6019f9e94910",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:10.208739018Z",
     "start_time": "2024-04-28T04:16:08.836862905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/mean_std.pkl\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    mean_std(f\"{ihm_discrete_save_path}/ts_train.pkl\", f\"{ihm_discrete_save_path}/mean_std.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407668b846604ce6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalizing timeseries data\n",
    "Now we apply normalization to our data by x = (x - means[f_idx]) / stds[f_idx], For this, we leverage the Normalizer provided by the mimic3-benchmarks repo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3b6d118f0c2f7865",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:13.292964988Z",
     "start_time": "2024-04-28T04:16:10.210075658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing train times data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/norm_ts_train.pkl\n",
      "Normalizing val times data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/norm_ts_val.pkl\n",
      "Normalizing test times data\n",
      "Saving: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/norm_ts_test.pkl\n"
     ]
    }
   ],
   "source": [
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    normalizer = Normalizer(fields=cont_channels)\n",
    "    normalizer.load_params(normalizer_state_file_path)\n",
    "\n",
    "    for dataset_type in dataset_types:\n",
    "        print(f\"Normalizing {dataset_type} times data\", flush=True)\n",
    "        normalize(f\"{ihm_discrete_save_path}/ts_{dataset_type}.pkl\",\n",
    "                  f\"{ihm_discrete_save_path}/norm_ts_{dataset_type}.pkl\",\n",
    "                  f\"{ihm_discrete_save_path}/mean_std.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef855063840a6659",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preparing the Text data\n",
    "We finally prepare the text data within a period (48 in our case) and generate a json containing the note as well as the time until the end of the period. For this we use the TextReader helper from the MultimodalMIMIC module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ae28b8cd4f293522",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:15.529060367Z",
     "start_time": "2024-04-28T04:16:13.297242765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing  train text data\n",
      "Suceed Merging:  750\n",
      "Missing Merging:  250\n",
      "File dumped at: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/trainp2x_data.pkl\n",
      "Preparing  val text data\n",
      "Suceed Merging:  750\n",
      "Missing Merging:  250\n",
      "File dumped at: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/valp2x_data.pkl\n",
      "Preparing  test text data\n",
      "Suceed Merging:  762\n",
      "Missing Merging:  238\n",
      "File dumped at: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/testp2x_data.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if GENERATE_PREPROCESSED_PKL:\n",
    "    for dataset_type in dataset_types:\n",
    "        print(f\"Preparing  {dataset_type} text data\", flush=True)\n",
    "\n",
    "        with open(f\"{ihm_discrete_save_path}/norm_ts_{dataset_type}.pkl\", 'rb') as f:\n",
    "            tsdata = pickle.load(f)\n",
    "\n",
    "        names = [data['name'] for data in tsdata]\n",
    "\n",
    "        if (dataset_type == 'train') or (dataset_type == 'val'):\n",
    "            text_reader = TextReader(textdata_fixed, text_start_time_path)\n",
    "        else:\n",
    "            text_reader = TextReader(test_textdata_fixed, test_text_start_time_path)\n",
    "\n",
    "        data_text, data_times, data_time = text_reader.read_all_text_append_json(names, mortality_period)\n",
    "        merge_text_ts(data_text, data_times, data_time, tsdata, mortality_period,\n",
    "                      f\"{ihm_discrete_save_path}/{dataset_type}p2x_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645f45acb9458e6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Preprocessing results\n",
    "After running the preprocessing we will obtain the pkl files that will be used by the model for training and evaluation. The following cell will show the structure of the main pkl files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c59c7556d383c71f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:15.597121430Z",
     "start_time": "2024-04-28T04:16:15.529332190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structure of the p2x pkl files\n",
      "Keys p2x: dict_keys(['reg_ts', 'name', 'label', 'ts_tt', 'irg_ts', 'irg_ts_mask', 'text_data', 'text_time_to_end'])\n",
      "Keys norm: dict_keys(['reg_ts', 'name', 'label', 'ts_tt', 'irg_ts', 'irg_ts_mask'])\n",
      "Keys mean_std tuple type : (<class 'list'>,<class 'list'>)\n"
     ]
    }
   ],
   "source": [
    "def display_p2x_pkl_structure():\n",
    "    print(\"Structure of the p2x pkl files\")\n",
    "    with open(f\"{ihm_discrete_save_path}/testp2x_data.pkl\", 'rb') as file:\n",
    "        p2x_data = pickle.load(file)\n",
    "        print(f\"Keys p2x: {p2x_data[0].keys()}\")\n",
    "\n",
    "    with open(f\"{ihm_discrete_save_path}/norm_ts_test.pkl\", 'rb') as file:\n",
    "        p2x_data = pickle.load(file)\n",
    "        print(f\"Keys norm: {p2x_data[0].keys()}\")\n",
    "\n",
    "    with open(f\"{ihm_discrete_save_path}/mean_std.pkl\", 'rb') as file:\n",
    "        p2x_data = pickle.load(file)\n",
    "        print(f\"Keys mean_std tuple type : ({type(p2x_data[0])},{type(p2x_data[0])})\")\n",
    "\n",
    "\n",
    "display_p2x_pkl_structure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea129f0ca6817b1b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d742c8dbf677eb5a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## import required module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d5c0d798e3e52fc7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:15.607869508Z",
     "start_time": "2024-04-28T04:16:15.597908884Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "sys.path.insert(0, 'MultimodalMIMIC')\n",
    "from GlobalConfigs import *\n",
    "from MultimodalMIMIC.model import *\n",
    "from MultimodalMIMIC.train import *\n",
    "from MultimodalMIMIC.checkpoint import *\n",
    "from accelerate import Accelerator\n",
    "from MultimodalMIMIC.interp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf6062fd6a39c7d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## set arguments\n",
    "\n",
    "this step is to set up parameter to set up how to train and evaluatate the model.\n",
    "\n",
    "here we only train the model for 1 epoch for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3ebe52b12edd5709",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:15.614882262Z",
     "start_time": "2024-04-28T04:16:15.600833339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'ihm', 'file_path': '/media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous', 'output_dir': 'run/TS_Text', 'tensorboard_dir': None, 'seed': 42, 'mode': 'train', 'modeltype': 'TS_Text', 'eval_score': ['auc', 'auprc', 'f1'], 'num_labels': 2, 'max_length': 512, 'pad_to_max_length': False, 'model_path': None, 'train_batch_size': 2, 'eval_batch_size': 8, 'num_update_bert_epochs': 2, 'num_train_epochs': 1, 'txt_learning_rate': 5e-05, 'ts_learning_rate': 0.0004, 'gradient_accumulation_steps': 16, 'weight_decay': 0.01, 'lr_scheduler_type': 'linear', 'pt_mask_ratio': 0.15, 'mean_mask_length': 3, 'chunk': False, 'chunk_type': 'sent_doc_pos', 'warmup_proportion': 0.1, 'kernel_size': 1, 'num_heads': 8, 'layers': 3, 'cross_layers': 3, 'embed_dim': 128, 'irregular_learn_emb_ts': True, 'irregular_learn_emb_text': True, 'reg_ts': True, 'tt_max': 48, 'embed_time': 64, 'ts_to_txt': False, 'txt_to_ts': False, 'dropout': 0.1, 'model_name': 'bioLongformer', 'num_of_notes': 5, 'notes_order': 'Last', 'ratio_notes_order': None, 'bertcount': 3, 'first_n_item': 3, 'fine_tune': False, 'self_cross': False, 'TS_mixup': False, 'mixup_level': 'batch', 'fp16': True, 'debug': False, 'generate_data': False, 'FTLSTM': False, 'Interp': False, 'cpu': False, 'datagereate_seed': 42, 'TS_model': 'Atten', 'cross_method': 'self_cross'}\n"
     ]
    }
   ],
   "source": [
    "from MultimodalMIMIC.util import parse_args\n",
    "\n",
    "parser = parse_args()\n",
    "args = parser.parse_args(['--num_train_epochs', f'{current_experiment.epochs}',\n",
    "                          '--train_batch_size', '2',\n",
    "                          '--eval_batch_size', '8',\n",
    "                          '--gradient_accumulation_steps', '16',\n",
    "                          '--num_update_bert_epochs', '2',\n",
    "                          '--notes_order', 'Last',\n",
    "                          '--max_length', f'{current_experiment.max_text_length}',\n",
    "                          '--output_dir', 'run/TS_Text',\n",
    "                          '--embed_dim', '128',\n",
    "                          '--model_name', 'bioLongformer',\n",
    "                          '--file_path', f'{ihm_discrete_save_path}',\n",
    "                          '--mixup_level', 'batch',\n",
    "                          '--fp16',\n",
    "                          '--irregular_learn_emb_text',\n",
    "                          '--irregular_learn_emb_ts',\n",
    "                          '--reg_ts'])\n",
    "\n",
    "print(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5545519ecc6bcd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Set up training environment\n",
    "\n",
    "based on given argument above, set up the training environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8001c7cfaa4a4ac9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:15.658609118Z",
     "start_time": "2024-04-28T04:16:15.615474919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "run/TS_Text/ihm/TS_Text/TS_48/Atten/Text_48/bioLongformer/512/cross_attn3/irregular_TS_64/irregular_Text_64/5e-05_2_3_0.0004_1_8_128_1_2/\n"
     ]
    }
   ],
   "source": [
    "if args.fp16:\n",
    "    args.mixed_precision = \"fp16\"\n",
    "else:\n",
    "    args.mixed_precision = \"no\"\n",
    "accelerator = Accelerator(mixed_precision=args.mixed_precision, cpu=args.cpu)\n",
    "\n",
    "device = accelerator.device\n",
    "print(f'device: {device}')\n",
    "os.makedirs(args.output_dir, exist_ok=True)\n",
    "if args.tensorboard_dir != None:\n",
    "    writer = SummaryWriter(args.tensorboard_dir)\n",
    "else:\n",
    "    writer = None\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed)\n",
    "\n",
    "output_path = make_save_dir(args)\n",
    "\n",
    "if args.seed == 0:\n",
    "    copy_file(args.ck_file_path + 'model/', src=os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0fe1b9546a9eac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load data\n",
    "\n",
    "Load training, validation and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bdfcf92446bfd606",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:16.642554720Z",
     "start_time": "2024-04-28T04:16:15.629145278Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerModel were not initialized from the model checkpoint at yikuan8/Clinical-Longformer and are newly initialized: ['longformer.pooler.dense.bias', 'longformer.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franco Trying to load: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/trainp2x_data.pkl\n",
      "Using /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/trainp2x_data.pkl\n",
      "Franco Trying to load: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/valp2x_data.pkl\n",
      "Using /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/valp2x_data.pkl\n",
      "Franco Trying to load: /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/testp2x_data.pkl\n",
      "Using /media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/Data/ihm_1000_previous/testp2x_data.pkl\n"
     ]
    }
   ],
   "source": [
    "from MultimodalMIMIC.data import data_perpare\n",
    "from MultimodalMIMIC.util import loadBert\n",
    "\n",
    "if args.mode == 'train':\n",
    "    if 'Text' in args.modeltype:\n",
    "        BioBert, BioBertConfig, tokenizer = loadBert(args, device)\n",
    "    else:\n",
    "        BioBert, tokenizer = None, None\n",
    "    train_dataset, train_sampler, train_dataloader = data_perpare(args, 'train', tokenizer)\n",
    "    val_dataset, val_sampler, val_dataloader = data_perpare(args, 'val', tokenizer)\n",
    "    _, _, test_data_loader = data_perpare(args, 'test', tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36408e5fb15eac2f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load model\n",
    "\n",
    "load model from model python.\n",
    "for full model implementation, check GitHub.\n",
    "\n",
    "based on given argument model type, the below code will load one of two models.\n",
    "\n",
    "- MULTCrossModel:\n",
    "  - This is a multi-modal cross model. It combines both text and time series data. Depending on the configuration, it may employ Transformer encoders for processing time series data and apply attention mechanisms for processing text embeddings. The model integrates text and time series data at different levels using various fusion techniques such as self-cross attention or cross-modal fusion. Again, the output depends on the task (ihm or pheno), and appropriate loss functions are used accordingly.\n",
    "- \n",
    "TSMixed\n",
    "  - This is a mixed model for time series data. It combines interpolation techniques, such as S_Interp and Cross_Interp, with Transformer-based encoders or other models like LSTM or CNN for processing time series data. It handles mixed-level data, such as batch-level, sequence-level, or feature-level mixup, and outputs predictions based on the task (ihm or pheno)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17d700490ade34",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![high level arch with desc](.img/high_arch_w_desc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7814a16c38a9b49c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:16.675638607Z",
     "start_time": "2024-04-28T04:16:16.646824352Z"
    }
   },
   "outputs": [],
   "source": [
    "if 'Text' in args.modeltype:\n",
    "    model = MULTCrossModel(args=args, device=device, orig_d_ts=17, orig_reg_d_ts=34, orig_d_txt=768,\n",
    "                           ts_seq_num=args.tt_max, text_seq_num=args.num_of_notes, Biobert=BioBert)\n",
    "else:\n",
    "    model = TSMixed(args=args, device=device, orig_d_ts=17, orig_reg_d_ts=34, ts_seq_num=args.tt_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357c72c29e3d47c1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## train\n",
    "\n",
    "This part of code train model. \n",
    "Given modeltype argument from above, it will set optimizer for different model type. (Text, Timeseries or mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a458eff6e7e8cbc8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:30.180009057Z",
     "start_time": "2024-04-28T04:16:16.668257077Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001B[A\n",
      "1it [00:00,  3.58it/s]\u001B[A\n",
      "2it [00:00,  3.29it/s]\u001B[A\n",
      "3it [00:00,  3.70it/s]\u001B[A\n",
      "4it [00:01,  2.63it/s]\u001B[A\n",
      "5it [00:01,  2.99it/s]\u001B[A\n",
      "6it [00:01,  3.30it/s]\u001B[A\n",
      "7it [00:02,  3.48it/s]\u001B[A\n",
      "8it [00:02,  3.62it/s]\u001B[A\n",
      "9it [00:02,  3.75it/s]\u001B[A\n",
      "10it [00:02,  3.94it/s]\u001B[A\n",
      "11it [00:03,  3.34it/s]\u001B[A\n",
      "12it [00:03,  3.48it/s]\u001B[A\n",
      "13it [00:03,  3.67it/s]\u001B[A\n",
      "14it [00:04,  3.76it/s]\u001B[A\n",
      "15it [00:04,  3.89it/s]\u001B[A\n",
      "16it [00:04,  3.87it/s]\u001B[A\n",
      "17it [00:04,  4.00it/s]\u001B[A\n",
      "18it [00:04,  4.07it/s]\u001B[A\n",
      "19it [00:05,  4.06it/s]\u001B[A\n",
      "20it [00:05,  4.01it/s]\u001B[A\n",
      "21it [00:05,  4.09it/s]\u001B[A\n",
      "22it [00:05,  3.93it/s]\u001B[A\n",
      "23it [00:06,  3.34it/s]\u001B[A\n",
      "24it [00:06,  3.47it/s]\u001B[A\n",
      "25it [00:07,  2.99it/s]\u001B[A\n",
      "26it [00:07,  2.49it/s]\u001B[A\n",
      "27it [00:08,  2.56it/s]\u001B[A\n",
      "28it [00:08,  2.26it/s]\u001B[A\n",
      "29it [00:08,  2.41it/s]\u001B[A\n",
      "30it [00:09,  2.73it/s]\u001B[A\n",
      "31it [00:09,  3.02it/s]\u001B[A\n",
      "32it [00:09,  3.27it/s]\u001B[A\n",
      "33it [00:09,  3.51it/s]\u001B[A\n",
      "34it [00:10,  3.60it/s]\u001B[A\n",
      "35it [00:10,  3.36it/s]\u001B[A\n",
      "36it [00:10,  2.92it/s]\u001B[A\n",
      "37it [00:11,  2.76it/s]\u001B[A\n",
      "38it [00:11,  3.04it/s]\u001B[A\n",
      "39it [00:11,  3.36it/s]\u001B[A\n",
      "40it [00:12,  3.00it/s]\u001B[A\n",
      "41it [00:12,  3.22it/s]\u001B[A\n",
      "42it [00:12,  3.50it/s]\u001B[A\n",
      "43it [00:12,  3.72it/s]\u001B[A\n",
      "44it [00:13,  3.30it/s]\u001B[A\n",
      "  0%|          | 0/1 [00:13<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[123], line 17\u001B[0m\n\u001B[1;32m     13\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     14\u001B[0m model, optimizer, train_dataloader, val_dataloader, test_data_loader \u001B[38;5;241m=\u001B[39m \\\n\u001B[1;32m     15\u001B[0m     accelerator\u001B[38;5;241m.\u001B[39mprepare(model, optimizer, train_dataloader, val_dataloader, test_data_loader)\n\u001B[0;32m---> 17\u001B[0m trainer_irg(model\u001B[38;5;241m=\u001B[39mmodel, args\u001B[38;5;241m=\u001B[39margs, accelerator\u001B[38;5;241m=\u001B[39maccelerator, train_dataloader\u001B[38;5;241m=\u001B[39mtrain_dataloader, \\\n\u001B[1;32m     18\u001B[0m             dev_dataloader\u001B[38;5;241m=\u001B[39mval_dataloader, test_data_loader\u001B[38;5;241m=\u001B[39mtest_data_loader, device\u001B[38;5;241m=\u001B[39mdevice, \\\n\u001B[1;32m     19\u001B[0m             optimizer\u001B[38;5;241m=\u001B[39moptimizer, writer\u001B[38;5;241m=\u001B[39mwriter)\n\u001B[1;32m     20\u001B[0m end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     21\u001B[0m current_experiment\u001B[38;5;241m.\u001B[39mtraining_time_millis \u001B[38;5;241m=\u001B[39m (end_time \u001B[38;5;241m-\u001B[39m start_time) \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1000\u001B[39m\n",
      "File \u001B[0;32m/media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/train.py:86\u001B[0m, in \u001B[0;36mtrainer_irg\u001B[0;34m(model, args, accelerator, train_dataloader, dev_dataloader, test_data_loader, device, optimizer, pretrain_epoch, writer, scheduler)\u001B[0m\n\u001B[1;32m     80\u001B[0m     loss \u001B[38;5;241m=\u001B[39m model(x_ts\u001B[38;5;241m=\u001B[39mts_input_sequences, \\\n\u001B[1;32m     81\u001B[0m                  x_ts_mask\u001B[38;5;241m=\u001B[39mts_mask_sequences, \\\n\u001B[1;32m     82\u001B[0m                  ts_tt_list\u001B[38;5;241m=\u001B[39mts_tt, \\\n\u001B[1;32m     83\u001B[0m                  labels\u001B[38;5;241m=\u001B[39mlabel, reg_ts\u001B[38;5;241m=\u001B[39mreg_ts)\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 86\u001B[0m     loss \u001B[38;5;241m=\u001B[39m model(x_ts\u001B[38;5;241m=\u001B[39mts_input_sequences, \\\n\u001B[1;32m     87\u001B[0m                  x_ts_mask\u001B[38;5;241m=\u001B[39mts_mask_sequences, \\\n\u001B[1;32m     88\u001B[0m                  ts_tt_list\u001B[38;5;241m=\u001B[39mts_tt, \\\n\u001B[1;32m     89\u001B[0m                  input_ids_sequences\u001B[38;5;241m=\u001B[39minput_ids_sequences, \\\n\u001B[1;32m     90\u001B[0m                  attn_mask_sequences\u001B[38;5;241m=\u001B[39mattn_mask_sequences, note_time_list\u001B[38;5;241m=\u001B[39mnote_time, \\\n\u001B[1;32m     91\u001B[0m                  note_time_mask_list\u001B[38;5;241m=\u001B[39mnote_time_mask, labels\u001B[38;5;241m=\u001B[39mlabel, reg_ts\u001B[38;5;241m=\u001B[39mreg_ts)\n\u001B[1;32m     92\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss \u001B[38;5;241m/\u001B[39m args\u001B[38;5;241m.\u001B[39mgradient_accumulation_steps\n\u001B[1;32m     93\u001B[0m accelerator\u001B[38;5;241m.\u001B[39mbackward(loss)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/accelerate/utils/operations.py:822\u001B[0m, in \u001B[0;36mconvert_outputs_to_fp32.<locals>.forward\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    821\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 822\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/accelerate/utils/operations.py:810\u001B[0m, in \u001B[0;36mConvertOutputsToFp32.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 810\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m convert_to_fp32(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_forward(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/amp/autocast_mode.py:16\u001B[0m, in \u001B[0;36mautocast_decorator.<locals>.decorate_autocast\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_autocast\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m autocast_instance:\n\u001B[0;32m---> 16\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/model.py:309\u001B[0m, in \u001B[0;36mMULTCrossModel.forward\u001B[0;34m(self, x_ts, x_ts_mask, ts_tt_list, input_ids_sequences, attn_mask_sequences, note_time_list, note_time_mask_list, labels, reg_ts)\u001B[0m\n\u001B[1;32m    307\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnknown time series type\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mText\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodeltype:\n\u001B[0;32m--> 309\u001B[0m     x_txt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbertrep(input_ids_sequences, attn_mask_sequences)\n\u001B[1;32m    310\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mirregular_learn_emb_text:\n\u001B[1;32m    311\u001B[0m         time_key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlearn_time_embedding(note_time_list)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/media/ftrujillo/FRD/Projects/UIUC/DLH/CS598_Final/MultimodalMIMIC/model.py:29\u001B[0m, in \u001B[0;36mBertForRepresentation.forward\u001B[0;34m(self, input_ids_sequence, attention_mask_sequence, sent_idx_list, doc_idx_list)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLongformer\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_name:\n\u001B[1;32m     27\u001B[0m     attention_mask \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m---> 29\u001B[0m     text_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbert(input_ids, global_attention_mask\u001B[38;5;241m=\u001B[39mattention_mask)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     31\u001B[0m     text_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbert(input_ids, attention_mask\u001B[38;5;241m=\u001B[39mattention_mask)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py:1738\u001B[0m, in \u001B[0;36mLongformerModel.forward\u001B[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1730\u001B[0m extended_attention_mask: torch\u001B[38;5;241m.\u001B[39mTensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_extended_attention_mask(attention_mask, input_shape)[\n\u001B[1;32m   1731\u001B[0m     :, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, :\n\u001B[1;32m   1732\u001B[0m ]\n\u001B[1;32m   1734\u001B[0m embedding_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membeddings(\n\u001B[1;32m   1735\u001B[0m     input_ids\u001B[38;5;241m=\u001B[39minput_ids, position_ids\u001B[38;5;241m=\u001B[39mposition_ids, token_type_ids\u001B[38;5;241m=\u001B[39mtoken_type_ids, inputs_embeds\u001B[38;5;241m=\u001B[39minputs_embeds\n\u001B[1;32m   1736\u001B[0m )\n\u001B[0;32m-> 1738\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(\n\u001B[1;32m   1739\u001B[0m     embedding_output,\n\u001B[1;32m   1740\u001B[0m     attention_mask\u001B[38;5;241m=\u001B[39mextended_attention_mask,\n\u001B[1;32m   1741\u001B[0m     head_mask\u001B[38;5;241m=\u001B[39mhead_mask,\n\u001B[1;32m   1742\u001B[0m     padding_len\u001B[38;5;241m=\u001B[39mpadding_len,\n\u001B[1;32m   1743\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1744\u001B[0m     output_hidden_states\u001B[38;5;241m=\u001B[39moutput_hidden_states,\n\u001B[1;32m   1745\u001B[0m     return_dict\u001B[38;5;241m=\u001B[39mreturn_dict,\n\u001B[1;32m   1746\u001B[0m )\n\u001B[1;32m   1747\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1748\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py:1318\u001B[0m, in \u001B[0;36mLongformerEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, padding_len, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1307\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1308\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m   1309\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1315\u001B[0m         output_attentions,\n\u001B[1;32m   1316\u001B[0m     )\n\u001B[1;32m   1317\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1318\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m layer_module(\n\u001B[1;32m   1319\u001B[0m         hidden_states,\n\u001B[1;32m   1320\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   1321\u001B[0m         layer_head_mask\u001B[38;5;241m=\u001B[39mhead_mask[idx] \u001B[38;5;28;01mif\u001B[39;00m head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   1322\u001B[0m         is_index_masked\u001B[38;5;241m=\u001B[39mis_index_masked,\n\u001B[1;32m   1323\u001B[0m         is_index_global_attn\u001B[38;5;241m=\u001B[39mis_index_global_attn,\n\u001B[1;32m   1324\u001B[0m         is_global_attn\u001B[38;5;241m=\u001B[39mis_global_attn,\n\u001B[1;32m   1325\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1326\u001B[0m     )\n\u001B[1;32m   1327\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n\u001B[1;32m   1330\u001B[0m     \u001B[38;5;66;03m# bzs x seq_len x num_attn_heads x (num_global_attn + attention_window_len + 1) => bzs x num_attn_heads x seq_len x (num_global_attn + attention_window_len + 1)\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py:1246\u001B[0m, in \u001B[0;36mLongformerLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001B[0m\n\u001B[1;32m   1236\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m   1237\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1238\u001B[0m     hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1244\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1245\u001B[0m ):\n\u001B[0;32m-> 1246\u001B[0m     self_attn_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattention(\n\u001B[1;32m   1247\u001B[0m         hidden_states,\n\u001B[1;32m   1248\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   1249\u001B[0m         layer_head_mask\u001B[38;5;241m=\u001B[39mlayer_head_mask,\n\u001B[1;32m   1250\u001B[0m         is_index_masked\u001B[38;5;241m=\u001B[39mis_index_masked,\n\u001B[1;32m   1251\u001B[0m         is_index_global_attn\u001B[38;5;241m=\u001B[39mis_index_global_attn,\n\u001B[1;32m   1252\u001B[0m         is_global_attn\u001B[38;5;241m=\u001B[39mis_global_attn,\n\u001B[1;32m   1253\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1254\u001B[0m     )\n\u001B[1;32m   1255\u001B[0m     attn_output \u001B[38;5;241m=\u001B[39m self_attn_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1256\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m self_attn_outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py:1182\u001B[0m, in \u001B[0;36mLongformerAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001B[0m\n\u001B[1;32m   1172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m   1173\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1174\u001B[0m     hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1180\u001B[0m     output_attentions\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   1181\u001B[0m ):\n\u001B[0;32m-> 1182\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself(\n\u001B[1;32m   1183\u001B[0m         hidden_states,\n\u001B[1;32m   1184\u001B[0m         attention_mask\u001B[38;5;241m=\u001B[39mattention_mask,\n\u001B[1;32m   1185\u001B[0m         layer_head_mask\u001B[38;5;241m=\u001B[39mlayer_head_mask,\n\u001B[1;32m   1186\u001B[0m         is_index_masked\u001B[38;5;241m=\u001B[39mis_index_masked,\n\u001B[1;32m   1187\u001B[0m         is_index_global_attn\u001B[38;5;241m=\u001B[39mis_index_global_attn,\n\u001B[1;32m   1188\u001B[0m         is_global_attn\u001B[38;5;241m=\u001B[39mis_global_attn,\n\u001B[1;32m   1189\u001B[0m         output_attentions\u001B[38;5;241m=\u001B[39moutput_attentions,\n\u001B[1;32m   1190\u001B[0m     )\n\u001B[1;32m   1191\u001B[0m     attn_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[1;32m   1192\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attn_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/DLH/lib/python3.11/site-packages/transformers/models/longformer/modeling_longformer.py:694\u001B[0m, in \u001B[0;36mLongformerSelfAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001B[0m\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;66;03m# The attention weights for tokens with global attention are\u001B[39;00m\n\u001B[1;32m    690\u001B[0m     \u001B[38;5;66;03m# just filler values, they were never used to compute the output.\u001B[39;00m\n\u001B[1;32m    691\u001B[0m     \u001B[38;5;66;03m# Fill with 0 now, the correct values are in 'global_attn_probs'.\u001B[39;00m\n\u001B[1;32m    692\u001B[0m     attn_probs[is_index_global_attn_nonzero] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 694\u001B[0m outputs \u001B[38;5;241m=\u001B[39m (attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m),)\n\u001B[1;32m    696\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n\u001B[1;32m    697\u001B[0m     outputs \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (attn_probs,)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "if args.modeltype == 'TS':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.ts_learning_rate)\n",
    "elif args.modeltype == 'Text' or args.modeltype == 'TS_Text':\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': [p for n, p in model.named_parameters() if 'bert' not in n]},\n",
    "        {'params': [p for n, p in model.named_parameters() if 'bert' in n], 'lr': args.txt_learning_rate}\n",
    "    ], lr=args.ts_learning_rate)\n",
    "else:\n",
    "    raise ValueError(\"Unknown modeltype in optimizer.\")\n",
    "\n",
    "start_time = time.time()\n",
    "model, optimizer, train_dataloader, val_dataloader, test_data_loader = \\\n",
    "    accelerator.prepare(model, optimizer, train_dataloader, val_dataloader, test_data_loader)\n",
    "\n",
    "trainer_irg(model=model, args=args, accelerator=accelerator, train_dataloader=train_dataloader, \\\n",
    "            dev_dataloader=val_dataloader, test_data_loader=test_data_loader, device=device, \\\n",
    "            optimizer=optimizer, writer=writer)\n",
    "end_time = time.time()\n",
    "current_experiment.training_time_millis = (end_time - start_time) * 1000\n",
    "print(f\"Training time: {current_experiment.training_time_millis} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bec66f34abf3c5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab0794ced7c8d7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T04:16:30.179688072Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from dataclasses import asdict\n",
    "\n",
    "\n",
    "def save_experiment(experiment: ModelExperiment, filename: str):\n",
    "    # Convert the dataclass to a dictionary\n",
    "    experiment_dict = asdict(experiment)\n",
    "\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, 'r') as f:\n",
    "            experiments = json.load(f)\n",
    "    else:\n",
    "        experiments = []\n",
    "\n",
    "    experiments.append(experiment_dict)\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(experiments, f, indent=4)\n",
    "\n",
    "\n",
    "eval_result = eval_test(args, model, test_data_loader, device)\n",
    "\n",
    "results = list(eval_result.values())[0]\n",
    "current_experiment.eval_auc_results = results[\"auc\"]\n",
    "current_experiment.eval_f1_results = results[\"f1\"]\n",
    "current_experiment.eval_auprc_results = results[\"auprc\"]\n",
    "save_experiment(current_experiment, f\"{PROJECT_BASE_PATH}/eval_results/experiments.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d6425b8566db17",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load evaluation result\n",
    "\n",
    "the performance of proposed methods and baselines are measured by the F1, AUPR, and AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea38aee8aebeaf7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:30.181494198Z",
     "start_time": "2024-04-28T04:16:30.180673801Z"
    }
   },
   "outputs": [],
   "source": [
    "for result_file in os.listdir(args.ck_file_path):\n",
    "    if 'result.pkl' in result_file:\n",
    "        eval_result_path = args.ck_file_path + result_file\n",
    "        # print(eval_result_path)\n",
    "        with open(eval_result_path, 'rb') as f:\n",
    "            evaluation_result = pickle.load(f)\n",
    "            print(evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f98a4705268e3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Experiment Results \n",
    "\n",
    "Since for the demonstration we only used 1000 sample for 1 epoch, and we fill in dummy data for entry with missing value, we could not achieve the same result as the paper describe.\n",
    "\n",
    "We plan to further furnish the code and run on the full sample data with more epoch, to see if we could get the result as the paper describe.\n",
    "\n",
    "Table of results (no need to include additional experiments, but main reproducibility result should be included)\n",
    "Create table and graph comparing different params (n epochs, etc.)\n",
    "All claims should be supported by experiment results\n",
    "Discuss with respect to the hypothesis and results from the original paper\n",
    "Experiments beyond the original paper\n",
    "Each experiment should include results and a discussion\n",
    "Ablation Study.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609fd938109d1e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Comparison between Hyperparameters\n",
    "\n",
    "| Experiment | N samples    | Epochs | Text Max Length | Learning Rate |\n",
    "|------------|--------------|--------|-----------------|---------------|\n",
    "| A          | Full Dataset | 1      | 1024            | 0.00002       |\n",
    "| B          | Full Dataset | 5      | 512             | 0.00002       |\n",
    "| C          | Full Dataset | 5      | 1024            | 0.00002       |\n",
    "| D          | 3000 samples | 1      | 1024            | 0.00002       |\n",
    "| E          | 3000 samples | 5      | 512             | 0.00002       |\n",
    "| F          | 3000 samples | 5      | 1024            | 0.00002       |\n",
    "| G          | Full Dataset | 10     | 1024            | 0.00002       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695942639bc99300",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-28T04:16:30.182294958Z",
     "start_time": "2024-04-28T04:16:30.181697982Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3042596241658c7c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Discussion and learnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e17be980100ea1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Implications of the experimental results\n",
    "The results of our experiments show the benefits of using the UTDE, mTAND and the cross modal fusion improves the performance of the model based on the F1 score. However, given the Hardware and time limitations we were unable to 100% reproduce the scores obtained by the authors. Specifically we used a lower amount of epochs for the training that have a direct impact on the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df67733eb99f6aeb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### What was easy\n",
    "The paper itself was very easy to understand on the theoretical side, the explanations for UTDE and mTAND concepts were very well explained and easy to understand. On the code side, even though it was not focussed on reproducibility we were able to reuse some of the code from the original authors and adapt it to our needs, specially the Model structure and some of the preprocessing steps. Also, as in the original paper, the mimic3-benchmarks and ClinicalNotesICU repos were very helpful to preprocess the original CSV datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e10a1c91d01d3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Challenges\n",
    "The main challenges we faced for the reproducibility of the paper were as follows:\n",
    "- The dependencies for the project were not documented or not included in the requirements.txt file. \n",
    "    - We manually had to check the code and the requirements.txt file to find the dependencies missing.\n",
    "- Requirements.txt file pointed to the local versions of the original authors and the versions were not compatible with the current versions of the libraries.\n",
    "    - We tested multiple versions of the libraries to find the compatible versions and updated the requirements.txt file accordingly.\n",
    "- Some libraries used for the original project were not available anymore or were experimental versions at the time of the original project implementation.\n",
    "    - We had to find an alternative version and syntax for the libraries for similar outcome. \n",
    "- The preprocessing steps were not straightforward, and were unable to process edge cases like missing values in the time series data or text data.\n",
    "    - We debug and  tested multiple approaches to fill or skip in the missing values and preprocess the data. We found the best outcome by filling the missing values with a \"NO_DATA\" token for text and time_to_end = 0 for time series data.\n",
    "- The original implementation did not take into account the different path formatting for different OS, which made it difficult to run the code on different OS.\n",
    "    - We introduced a GlobalConfigs.py file to set up the local path to the project and used it in the code to make it OS independent. \n",
    "- The configuration arguments for the original code were not documented and had not descriptive names and given the amount of data folders and pkls it was difficult to understand the code and requirements for each part.\n",
    "    - We added descriptive names to the configuration variables on GlobalConfigs.py as well as composing the subdirectories based on the relative paths.\n",
    "- There was no information about the repo version or commit hash used for the mimic3-benchmarks and ClinicalNotesICU repos, since the external projects changed the output formats and the file naming we had to update the code to make these inputs interchangeable.\n",
    "    - We modify the code to use the new file naming and output formats from the mimic3-benchmarks and ClinicalNotesICU repos and add variables to configure these files in the notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c20c815f0a61aad",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Recommendations to the original authors\n",
    "Based on our experience, we recommend the following to the original authors for improving reproducibility:\n",
    "- Document the dependencies and the versions of the libraries used in the project.\n",
    "- Use the requirements.txt file to list all the dependencies and their versions making sure they are publicly available.\n",
    "- Document Hardware used for the experiments, as the project requires a lot of computational resources.\n",
    "- Document the configuration arguments used for the project and provide a description for each argument.\n",
    "- Provide the folder structure and the expected output on the environment where the project was developed.\n",
    "- Provide the version of the external projects used in the project and the commit hash for the external projects.\n",
    "- Provide sample input required for the model training and evaluation.\n",
    "- Provide details about the dataset and how to get access to it if it is not publicly available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c7f291f7d6a1d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-28T04:16:30.192906989Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
